format 75
"build" // build
  revision 117
  modified_by 48 "finnerty"
  owner 48 "finnerty"
  // class settings
  //class diagram settings
  draw_all_relations default hide_attributes default hide_operations default hide_getset_operations default show_members_full_definition default show_members_visibility default show_members_stereotype default show_members_context default show_members_multiplicity default show_members_initialization default show_attribute_modifiers default member_max_width 0 show_parameter_dir default show_parameter_name default package_name_in_tab default class_drawing_mode default drawing_language default show_context_mode default auto_label_position default show_relation_modifiers default show_relation_visibility default show_infonote default shadow default show_stereotype_properties default
  //use case diagram settings
  package_name_in_tab default show_context default auto_label_position default draw_all_relations default class_drawing_mode default shadow default show_stereotype_properties default
  //sequence diagram settings
  show_full_operations_definition default write_horizontally default class_drawing_mode default drawing_language default draw_all_relations default shadow default show_stereotype_properties default show_class_context_mode default show_msg_context_mode default
  //collaboration diagram settings
  show_full_operations_definition default show_hierarchical_rank default write_horizontally default drawing_language default package_name_in_tab default show_context default show_msg_context default draw_all_relations default shadow default show_stereotype_properties default
  //object diagram settings
   write_horizontally default package_name_in_tab default show_context default auto_label_position default draw_all_relations default shadow default show_stereotype_properties default
  //component diagram settings
  package_name_in_tab default show_context default auto_label_position default draw_all_relations default shadow default
  draw_component_as_icon default show_component_req_prov default show_component_rea default show_stereotype_properties default
  //deployment diagram settings
  package_name_in_tab default show_context default write_horizontally default auto_label_position default draw_all_relations default shadow default
  draw_component_as_icon default show_component_req_prov default show_component_rea default show_stereotype_properties default
  //state diagram settings
  package_name_in_tab default show_context default auto_label_position default write_trans_label_horizontally default show_trans_definition default draw_all_relations default shadow default
  show_activities default region_horizontally default drawing_language default show_stereotype_properties default
  //activity diagram settings
  package_name_in_tab default show_context default show_opaque_action_definition default auto_label_position default write_flow_label_horizontally default draw_all_relations default shadow default
  show_infonote default drawing_language default show_stereotype_properties default
  
  cpp_h_dir ".."
  cpp_src_dir ".."
  deploymentview 128175 "config"
    //deployment diagram settings
    package_name_in_tab default show_context default write_horizontally default auto_label_position default draw_all_relations default shadow default
    draw_component_as_icon default show_component_req_prov default show_component_rea default show_stereotype_properties default
    artifact 183471 "buildfile"
      associated_artifacts
      end
      comment "${butter_boost}
using gcc : : : <cxxflags>\"-std=c++98 -Weffc++ -Woverloaded-virtual -Wstrict-null-sentinel\" <linkflags>\"-lz\" <optimization>speed:<cflags>\"-march=native -mfpmath=sse,387 -msse2\" ;
# using intel : : :  <cxxflags>\"-D_BOOL -wd383,981,869\" <linkflags>\"-i_dynamic -rdynamic -lz\" <optimization>speed:<cflags>\"-tpp7 -xW -ipo\" ;"
    end

    artifact 183855 "gcc-opt.txt"
      associated_artifacts
      end
      comment "GCC defined macros
=================

gcc -dM -E - < /dev/null

GCC Options That Control Optimization
======================================

These options control various sorts of optimizations.

 Without any optimization option, the compiler's goal is to reduce the
cost of compilation and to make debugging produce the expected results.
Statements are independent: if you stop the program with a breakpoint
between statements, you can then assign a new value to any variable or
change the program counter to any other statement in the function and
get exactly the results you would expect from the source code.

 Turning on optimization flags makes the compiler attempt to improve
the performance and/or code size at the expense of compilation time and
possibly the ability to debug the program.

 The compiler performs optimization based on the knowledge it has of
the program.  Optimization levels `-O' and above, in particular, enable
_unit-at-a-time_ mode, which allows the compiler to consider
information gained from later functions in the file when compiling a
function.  Compiling multiple files at once to a single output file in
_unit-at-a-time_ mode allows the compiler to use information gained
from all of the files when compiling each of them.

 Not all optimizations are controlled directly by a flag.  Only
optimizations that have a flag are listed.

`-O'
`-O1'
     Optimize.  Optimizing compilation takes somewhat more time, and a
     lot more memory for a large function.

     With `-O', the compiler tries to reduce code size and execution
     time, without performing any optimizations that take a great deal
     of compilation time.

     `-O' turns on the following optimization flags:
          -fguess-branch-probability

`-O2'
     Optimize even more.  GCC performs nearly all supported
     optimizations that do not involve a space-speed tradeoff.  The
     compiler does not perform loop unrolling or function inlining when
     you specify `-O2'.  As compared to `-O', this option increases
     both compilation time and the performance of the generated code.

     `-O2' turns on all optimization flags specified by `-O'.  It also
     turns on the following optimization flags:
          -fstrict-aliasing

     Please note the warning under `-fgcse' about invoking `-O2' on
     programs that use computed gotos.

`-O3'
     Optimize yet more. 
`-O0'
     Do not optimize.  This is the default.

`-Os'
     Optimize for size.  `-Os' enables all `-O2' optimizations that do
     not typically increase code size.  It also performs further
     optimizations designed to reduce code size.

     `-Os' disables the following optimization flags:
          -falign-functions  -falign-jumps  -falign-loops
          -falign-labels  -freorder-blocks  -freorder-blocks-and-partition
          -fprefetch-loop-arrays  -ftree-vect-loop-version

     If you use multiple `-O' options, with or without level numbers,
     the last such option is the one that is effective.

 Options of the form `-fFLAG' specify machine-independent flags.  Most
flags have both positive and negative forms; the negative form of
`-ffoo' would be `-fno-foo'.  In the table below, only one of the forms
is listed--the one you typically will use.  You can figure out the
other form by either removing `no-' or adding it.

 The following options control specific optimizations.  They are either
activated by `-O' options or are related to ones that are.  You can use
the following flags in the rare cases when \"fine-tuning\" of
optimizations to be performed is desired.

`-fno-default-inline'
     Do not make member functions inline by default merely because they
     are defined inside the class scope (C++ only).  Otherwise, when
     you specify `-O', member functions defined inside class scope are
     compiled inline by default; i.e., you don't need to add `inline'
     in front of the member function name.

`-fforce-addr'
     Force memory address constants to be copied into registers before
     doing arithmetic on them.

`-fno-inline'
     Don't pay attention to the `inline' keyword.  Normally this option
     is used to keep the compiler from expanding any functions inline.
     Note that if you are not optimizing, no functions can be expanded
     inline.

`-finline-limit=N'
     By default, GCC limits the size of functions that can be inlined.
     This flag allows the control of this limit for functions that are
     explicitly marked as inline (i.e., marked with the inline keyword
     or defined within the class definition in c++).  N is the size of
     functions that can be inlined in number of pseudo instructions
     (not counting parameter handling).  The default value of N is 600.
     Increasing this value can result in more inlined code at the cost
     of compilation time and memory consumption.  Decreasing usually
     makes the compilation faster and less code will be inlined (which
     presumably means slower programs).  This option is particularly
     useful for programs that use inlining heavily such as those based
     on recursive templates with C++.

     Inlining is actually controlled by a number of parameters, which
     may be specified individually by using `--param NAME=VALUE'.  The
     `-finline-limit=N' option sets some of these parameters as follows:

    `max-inline-insns-single'
          is set to N/2.

    `max-inline-insns-auto'
          is set to N/2.

    `min-inline-insns'
          is set to 130 or N/4, whichever is smaller.

    `max-inline-insns-rtl'
          is set to N.

     See below for a documentation of the individual parameters
     controlling inlining.

     _Note:_ pseudo instruction represents, in this particular context,
     an abstract measurement of function's size.  In no way does it
     represent a count of assembly instructions and as such its exact
     meaning might change from one release to an another.

`-fkeep-inline-functions'
     In C, emit `static' functions that are declared `inline' into the
     object file, even if the function has been inlined into all of its
     callers.  This switch does not affect functions using the `extern
     inline' extension in GNU C.  In C++, emit any and all inline
     functions into the object file.

`-fkeep-static-consts'
     Emit variables declared `static const' when optimization isn't
     turned on, even if the variables aren't referenced.

     GCC enables this option by default.  If you want to force the
     compiler to check if the variable was referenced, regardless of
     whether or not optimization is turned on, use the
     `-fno-keep-static-consts' option.

`-fmerge-all-constants'
     Attempt to merge identical constants and identical variables.

     This option implies `-fmerge-constants'.  In addition to
     `-fmerge-constants' this considers e.g. even constant initialized
     arrays or initialized constant variables with integral or floating
     point types.  Languages like C or C++ require each non-automatic
     variable to have distinct location, so using this option will
     result in non-conforming behavior.

`-fmodulo-sched'
     Perform swing modulo scheduling immediately before the first
     scheduling pass.  This pass looks at innermost loops and reorders
     their instructions by overlapping different iterations.

`-fno-branch-count-reg'
     Do not use \"decrement and branch\" instructions on a count register,
     but instead generate a sequence of instructions that decrement a
     register, compare it against zero, then branch based upon the
     result.  This option is only meaningful on architectures that
     support such instructions, which include x86, PowerPC, IA-64 and
     S/390.

     The default is `-fbranch-count-reg'.

`-fno-function-cse'
     Do not put function addresses in registers; make each instruction
     that calls a constant function contain the function's address
     explicitly.

     This option results in less efficient code, but some strange hacks
     that alter the assembler output may be confused by the
     optimizations performed when this option is not used.

     The default is `-ffunction-cse'

`-fno-zero-initialized-in-bss'
     If the target supports a BSS section, GCC by default puts
     variables that are initialized to zero into BSS.  This can save
     space in the resulting code.

     This option turns off this behavior because some programs
     explicitly rely on variables going to the data section.  E.g., so
     that the resulting executable can find the beginning of that
     section and/or make assumptions based on that.

     The default is `-fzero-initialized-in-bss'.

`-fbounds-check'
     For front-ends that support it, generate additional code to check
     that indices used to access arrays are within the declared range.
     This is currently only supported by the Java and Fortran
     front-ends, where this option defaults to true and false
     respectively.

`-ffortify'
`-ffortify=N'
     Instrument a set of string, memory and printf related functions
     into their _chk variants. N controls the behaviour in detail. A
     fortify level of 1 will produce compile warnings, but expand the
     _chk variants back into the non-checking equivalent, and therefore
     not introduce any run-time overhead in the generated code. A level
     of 2 will emit calls to the _chk variants if the overflow checking
     can only be done during runtime. Higher fortify levels are passed
     down to the printf related check functions and might control
     further fortify levels. A level of 0 disables the instrumentation.

`-fmudflap -fmudflapth -fmudflapir'
     For front-ends that support it (C and C++), instrument all risky
     pointer/array dereferencing operations, some standard library
     string/heap functions, and some other associated constructs with
     range/validity tests.  Modules so instrumented should be immune to
     buffer overflows, invalid heap use, and some other classes of C/C++
     programming errors.  The instrumentation relies on a separate
     runtime library (`libmudflap'), which will be linked into a
     program if `-fmudflap' is given at link time.  Run-time behavior
     of the instrumented program is controlled by the `MUDFLAP_OPTIONS'
     environment variable.  See `env MUDFLAP_OPTIONS=-help a.out' for
     its options.

     Use `-fmudflapth' instead of `-fmudflap' to compile and to link if
     your program is multi-threaded.  Use `-fmudflapir', in addition to
     `-fmudflap' or `-fmudflapth', if instrumentation should ignore
     pointer reads.  This produces less instrumentation (and therefore
     faster execution) and still provides some protection against
     outright memory corrupting writes, but allows erroneously read
     data to propagate within a program.

`-fgcse-sm'
     When `-fgcse-sm' is enabled, a store motion pass is run after
     global common subexpression elimination.  This pass will attempt
     to move stores out of loops.  When used in conjunction with
     `-fgcse-lm', loops containing a load/store sequence can be changed
     to a load before the loop and a store after the loop.

     Not enabled at any optimization level.

`-fgcse-las'
     When `-fgcse-las' is enabled, the global common subexpression
     elimination pass eliminates redundant loads that come after stores
     to the same memory location (both partial and full redundancies).

     Not enabled at any optimization level.

`-funsafe-loop-optimizations'
     If given, the loop optimizer will assume that loop indices do not
     overflow, and that the loops with nontrivial exit condition are not
     infinite.  This enables a wider range of loop optimizations even if
     the loop optimizer itself cannot prove that these assumptions are
     valid.  Using `-Wunsafe-loop-optimizations', the compiler will
     warn you if it finds this kind of loop.

`-fsched-stalled-insns=N'
     Define how many insns (if any) can be moved prematurely from the
     queue of stalled insns into the ready list, during the second
     scheduling pass.

`-fsched-stalled-insns-dep=N'
     Define how many insn groups (cycles) will be examined for a
     dependency on a stalled insn that is candidate for premature
     removal from the queue of stalled insns.  Has an effect only
     during the second scheduling pass, and only if
     `-fsched-stalled-insns' is used and its value is not zero.

`-fsched2-use-superblocks'
     When scheduling after register allocation, do use superblock
     scheduling algorithm.  Superblock scheduling allows motion across
     basic block boundaries resulting on faster schedules.  This option
     is experimental, as not all machine descriptions used by GCC model
     the CPU closely enough to avoid unreliable results from the
     algorithm.

     This only makes sense when scheduling after register allocation,
     i.e. with `-fschedule-insns2' or at `-O2' or higher.

`-fsched2-use-traces'
     Use `-fsched2-use-superblocks' algorithm when scheduling after
     register allocation and additionally perform code duplication in
     order to increase the size of superblocks using tracer pass.  See
     `-ftracer' for details on trace formation.

     This mode should produce faster but significantly longer programs.
     Also without `-fbranch-probabilities' the traces constructed may
     not match the reality and hurt the performance.  This only makes
     sense when scheduling after register allocation, i.e. with
     `-fschedule-insns2' or at `-O2' or higher.

`-fsee'
     Eliminates redundant extension instructions and move the non
     redundant ones to optimal placement using LCM.

`-freschedule-modulo-scheduled-loops'
     The modulo scheduling comes before the traditional scheduling, if
     a loop was modulo scheduled we may want to prevent the later
     scheduling passes from changing its schedule, we use this option
     to control that.

`-fipa-pta'
     Perform interprocedural pointer analysis.

`-ftree-loop-linear'
     Perform linear loop transformations on tree.  This flag can
     improve cache performance and allow further loop optimizations to
     take place.

`-ftree-loop-im'
     Perform loop invariant motion on trees.  This pass moves only
     invariants that would be hard to handle at RTL level (function
     calls, operations that expand to nontrivial sequences of insns).
     With `-funswitch-loops' it also moves operands of conditions that
     are invariant out of the loop, so that we can use just trivial
     invariantness analysis in loop unswitching.  The pass also includes
     store motion.

`-ftree-loop-ivcanon'
     Create a canonical counter for number of iterations in the loop
     for that determining number of iterations requires complicated
     analysis.  Later optimizations then may determine the number
     easily.  Useful especially in connection with unrolling.

`-fivopts'
     Perform induction variable optimizations (strength reduction,
     induction variable merging and induction variable elimination) on
     trees.

`-ftree-vectorize'
     Perform loop vectorization on trees.

`-ftracer'
     Perform tail duplication to enlarge superblock size.  This
     transformation simplifies the control flow of the function
     allowing other optimizations to do better job.

`-funroll-loops'
     Unroll loops whose number of iterations can be determined at
     compile time or upon entry to the loop.  `-funroll-loops' implies
     `-frerun-cse-after-loop'.  This option makes code larger, and may
     or may not make it run faster.

`-funroll-all-loops'
     Unroll all loops, even if their number of iterations is uncertain
     when the loop is entered.  This usually makes programs run more
     slowly.  `-funroll-all-loops' implies the same options as
     `-funroll-loops',

`-fsplit-ivs-in-unroller'
     Enables expressing of values of induction variables in later
     iterations of the unrolled loop using the value in the first
     iteration.  This breaks long dependency chains, thus improving
     efficiency of the scheduling passes.

     Combination of `-fweb' and CSE is often sufficient to obtain the
     same effect.  However in cases the loop body is more complicated
     than a single basic block, this is not reliable.  It also does not
     work at all on some of the architectures due to restrictions in
     the CSE pass.

     This optimization is enabled by default.

`-fvariable-expansion-in-unroller'
     With this option, the compiler will create multiple copies of some
     local variables when unrolling a loop which can result in superior
     code.

`-fprefetch-loop-arrays'
     If supported by the target machine, generate instructions to
     prefetch memory to improve the performance of loops that access
     large arrays.

     This option may generate better or worse code; results are highly
     dependent on the structure of loops within the source code.

     Disabled at level `-Os'.

`-fno-guess-branch-probability'
     Do not guess branch probabilities using heuristics.

     GCC will use heuristics to guess branch probabilities if they are
     not provided by profiling feedback (`-fprofile-arcs').  These
     heuristics are based on the control flow graph.  If some branch
     probabilities are specified by `__builtin_expect', then the
     heuristics will be used to guess branch probabilities for the rest
     of the control flow graph, taking the `__builtin_expect' info into
     account.  The interactions between the heuristics and
     `__builtin_expect' can be complex, and in some cases, it may be
     useful to disable the heuristics so that the effects of
     `__builtin_expect' are easier to understand.

     The default is `-fguess-branch-probability' at levels `-O', `-O2',
     `-O3', `-Os'.

`-freorder-blocks-and-partition'
     In addition to reordering basic blocks in the compiled function,
     in order to reduce number of taken branches, partitions hot and
     cold basic blocks into separate sections of the assembly and .o
     files, to improve paging and cache locality performance.

     This optimization is automatically turned off in the presence of
     exception handling, for linkonce sections, for functions with a
     user-defined section attribute and on any architecture that does
     not support named sections.

`-fstrict-aliasing'
     Allows the compiler to assume the strictest aliasing rules
     applicable to the language being compiled.  For C (and C++), this
     activates optimizations based on the type of expressions.  In
     particular, an object of one type is assumed never to reside at
     the same address as an object of a different type, unless the
     types are almost the same.  For example, an `unsigned int' can
     alias an `int', but not a `void*' or a `double'.  A character type
     may alias any other type.

     Pay special attention to code like this:
          union a_union {
            int i;
            double d;
          };

          int f() {
            a_union t;
            t.d = 3.0;
            return t.i;
          }
     The practice of reading from a different union member than the one
     most recently written to (called \"type-punning\") is common.  Even
     with `-fstrict-aliasing', type-punning is allowed, provided the
     memory is accessed through the union type.  So, the code above
     will work as expected.  However, this code might not:
          int f() {
            a_union t;
            int* ip;
            t.d = 3.0;
            ip = &t.i;
            return *ip;
          }

     Every language that wishes to perform language-specific alias
     analysis should define a function that computes, given an `tree'
     node, an alias set for the node.  Nodes in different alias sets
     are not allowed to alias.  For an example, see the C front-end
     function `c_get_alias_set'.

     Enabled at levels `-O2', `-O3', `-Os'.

`-fno-toplevel-reorder'
     Do not reorder top-level functions, variables, and `asm'
     statements.  Output them in the same order that they appear in the
     input file.  When this option is used, unreferenced static
     variables will not be removed.  This option is intended to support
     existing code which relies on a particular ordering.  For new
     code, it is better to use attributes.

`-fweb'
     Constructs webs as commonly used for register allocation purposes
     and assign each web individual pseudo register.  This allows the
     register allocation pass to operate on pseudos directly, but also
     strengthens several other optimization passes, such as CSE, loop
     optimizer and trivial dead code remover.  It can, however, make
     debugging impossible, since variables will no longer stay in a
     \"home register\".

     Enabled by default with `-funroll-loops'.

`-fwhole-program'
     Assume that the current compilation unit represents whole program
     being compiled.  All public functions and variables with the
     exception of `main' and those merged by attribute
     `externally_visible' become static functions and in a affect gets
     more aggressively optimized by interprocedural optimizers.  While
     this option is equivalent to proper use of `static' keyword for
     programs consisting of single file, in combination with option
     `--combine' this flag can be used to compile most of smaller scale
     C programs since the functions and variables become local for the
     whole combined compilation unit, not for the single source file
     itself.

`-fprofile-generate'
     Enable options usually used for instrumenting application to
     produce profile useful for later recompilation with profile
     feedback based optimization.  You must use `-fprofile-generate'
     both when compiling and when linking your program.

     The following options are enabled: `-fprofile-arcs',
     `-fprofile-values', `-fvpt'.

`-fprofile-use'
     Enable profile feedback directed optimizations, and optimizations
     generally profitable only with profile feedback available.

     The following options are enabled: `-fbranch-probabilities',
     `-fvpt', `-funroll-loops', `-fpeel-loops', `-ftracer'


 The following options control compiler behavior regarding floating
point arithmetic.  These options trade off between speed and
correctness.  All must be specifically enabled.

`-ffloat-store'
     Do not store floating point variables in registers, and inhibit
     other options that might change whether a floating point value is
     taken from a register or memory.

     This option prevents undesirable excess precision on machines such
     as the 68000 where the floating registers (of the 68881) keep more
     precision than a `double' is supposed to have.  Similarly for the
     x86 architecture.  For most programs, the excess precision does
     only good, but a few programs rely on the precise definition of
     IEEE floating point.  Use `-ffloat-store' for such programs, after
     modifying them to store all pertinent intermediate computations
     into variables.

`-ffast-math'
     Sets `-fno-math-errno', `-funsafe-math-optimizations',
     `-fno-trapping-math', `-ffinite-math-only', `-fno-rounding-math',
     `-fno-signaling-nans' and `fcx-limited-range'.

     This option causes the preprocessor macro `__FAST_MATH__' to be
     defined.

     This option should never be turned on by any `-O' option since it
     can result in incorrect output for programs which depend on an
     exact implementation of IEEE or ISO rules/specifications for math
     functions.

`-fno-math-errno'
     Do not set ERRNO after calling math functions that are executed
     with a single instruction, e.g., sqrt.  A program that relies on
     IEEE exceptions for math error handling may want to use this flag
     for speed while maintaining IEEE arithmetic compatibility.

     This option should never be turned on by any `-O' option since it
     can result in incorrect output for programs which depend on an
     exact implementation of IEEE or ISO rules/specifications for math
     functions.

     The default is `-fmath-errno'.

     On Darwin systems, the math library never sets `errno'.  There is
     therefore no reason for the compiler to consider the possibility
     that it might, and `-fno-math-errno' is the default.

`-funsafe-math-optimizations'
     Allow optimizations for floating-point arithmetic that (a) assume
     that arguments and results are valid and (b) may violate IEEE or
     ANSI standards.  When used at link-time, it may include libraries
     or startup files that change the default FPU control word or other
     similar optimizations.

     This option should never be turned on by any `-O' option since it
     can result in incorrect output for programs which depend on an
     exact implementation of IEEE or ISO rules/specifications for math
     functions.

     The default is `-fno-unsafe-math-optimizations'.

`-ffinite-math-only'
     Allow optimizations for floating-point arithmetic that assume that
     arguments and results are not NaNs or +-Infs.

     This option should never be turned on by any `-O' option since it
     can result in incorrect output for programs which depend on an
     exact implementation of IEEE or ISO rules/specifications.

     The default is `-fno-finite-math-only'.

`-fno-trapping-math'
     Compile code assuming that floating-point operations cannot
     generate user-visible traps.  These traps include division by
     zero, overflow, underflow, inexact result and invalid operation.
     This option implies `-fno-signaling-nans'.  Setting this option
     may allow faster code if one relies on \"non-stop\" IEEE arithmetic,
     for example.

     This option should never be turned on by any `-O' option since it
     can result in incorrect output for programs which depend on an
     exact implementation of IEEE or ISO rules/specifications for math
     functions.

     The default is `-ftrapping-math'.

`-frounding-math'
     Disable transformations and optimizations that assume default
     floating point rounding behavior.  This is round-to-zero for all
     floating point to integer conversions, and round-to-nearest for
     all other arithmetic truncations.  This option should be specified
     for programs that change the FP rounding mode dynamically, or that
     may be executed with a non-default rounding mode.  This option
     disables constant folding of floating point expressions at
     compile-time (which may be affected by rounding mode) and
     arithmetic transformations that are unsafe in the presence of
     sign-dependent rounding modes.

     The default is `-fno-rounding-math'.

     This option is experimental and does not currently guarantee to
     disable all GCC optimizations that are affected by rounding mode.
     Future versions of GCC may provide finer control of this setting
     using C99's `FENV_ACCESS' pragma.  This command line option will
     be used to specify the default state for `FENV_ACCESS'.

`-frtl-abstract-sequences'
     It is a size optimization method. This option is to find identical
     sequences of code, which can be turned into pseudo-procedures  and
     then  replace  all  occurrences with  calls to  the  newly created
     subroutine. It is kind of an opposite of `-finline-functions'.
     This optimization runs at RTL level.

`-fsignaling-nans'
     Compile code assuming that IEEE signaling NaNs may generate
     user-visible traps during floating-point operations.  Setting this
     option disables optimizations that may change the number of
     exceptions visible with signaling NaNs.  This option implies
     `-ftrapping-math'.

     This option causes the preprocessor macro `__SUPPORT_SNAN__' to be
     defined.

     The default is `-fno-signaling-nans'.

     This option is experimental and does not currently guarantee to
     disable all GCC optimizations that affect signaling NaN behavior.

`-fsingle-precision-constant'
     Treat floating point constant as single precision constant instead
     of implicitly converting it to double precision constant.

`-fcx-limited-range'
`-fno-cx-limited-range'
     When enabled, this option states that a range reduction step is not
     needed when performing complex division.  The default is
     `-fno-cx-limited-range', but is enabled by `-ffast-math'.

     This option controls the default setting of the ISO C99
     `CX_LIMITED_RANGE' pragma.  Nevertheless, the option applies to
     all languages.


 The following options control optimizations that may improve
performance, but are not enabled by any `-O' options.  This section
includes experimental options that may produce broken code.

`-fbranch-probabilities'
     After running a program compiled with `-fprofile-arcs' (*note
     Options for Debugging Your Program or `gcc': Debugging Options.),
     you can compile it a second time using `-fbranch-probabilities',
     to improve optimizations based on the number of times each branch
     was taken.  When the program compiled with `-fprofile-arcs' exits
     it saves arc execution counts to a file called `SOURCENAME.gcda'
     for each source file  The information in this data file is very
     dependent on the structure of the generated code, so you must use
     the same source code and the same optimization options for both
     compilations.

     With `-fbranch-probabilities', GCC puts a `REG_BR_PROB' note on
     each `JUMP_INSN' and `CALL_INSN'.  These can be used to improve
     optimization.  Currently, they are only used in one place: in
     `reorg.c', instead of guessing which path a branch is mostly to
     take, the `REG_BR_PROB' values are used to exactly determine which
     path is taken more often.

`-fprofile-values'
     If combined with `-fprofile-arcs', it adds code so that some data
     about values of expressions in the program is gathered.

     With `-fbranch-probabilities', it reads back the data gathered
     from profiling values of expressions and adds `REG_VALUE_PROFILE'
     notes to instructions for their later usage in optimizations.

     Enabled with `-fprofile-generate' and `-fprofile-use'.

`-fvpt'
     If combined with `-fprofile-arcs', it instructs the compiler to add
     a code to gather information about values of expressions.

     With `-fbranch-probabilities', it reads back the data gathered and
     actually performs the optimizations based on them.  Currently the
     optimizations include specialization of division operation using
     the knowledge about the value of the denominator.

`-frename-registers'
     Attempt to avoid false dependencies in scheduled code by making use
     of registers left over after register allocation.  This
     optimization will most benefit processors with lots of registers.
     Depending on the debug information format adopted by the target,
     however, it can make debugging impossible, since variables will no
     longer stay in a \"home register\".

     Enabled by default with `-funroll-loops'.

`-ftracer'
     Perform tail duplication to enlarge superblock size.  This
     transformation simplifies the control flow of the function
     allowing other optimizations to do better job.

     Enabled with `-fprofile-use'.

`-funroll-loops'
     Unroll loops whose number of iterations can be determined at
     compile time or upon entry to the loop.  `-funroll-loops' implies
     `-frerun-cse-after-loop', `-fweb' and `-frename-registers'.  It
     also turns on complete loop peeling (i.e. complete removal of
     loops with small constant number of iterations).  This option
     makes code larger, and may or may not make it run faster.

     Enabled with `-fprofile-use'.

`-funroll-all-loops'
     Unroll all loops, even if their number of iterations is uncertain
     when the loop is entered.  This usually makes programs run more
     slowly.  `-funroll-all-loops' implies the same options as
     `-funroll-loops'.

`-fpeel-loops'
     Peels the loops for that there is enough information that they do
     not roll much (from profile feedback).  It also turns on complete
     loop peeling (i.e. complete removal of loops with small constant
     number of iterations).

     Enabled with `-fprofile-use'.

`-ffunction-sections'
`-fdata-sections'
     Place each function or data item into its own section in the output
     file if the target supports arbitrary sections.  The name of the
     function or the name of the data item determines the section's name
     in the output file.

     Use these options on systems where the linker can perform
     optimizations to improve locality of reference in the instruction
     space.  Most systems using the ELF object format and SPARC
     processors running Solaris 2 have linkers with such optimizations.
     AIX may have these optimizations in the future.

     Only use these options when there are significant benefits from
     doing so.  When you specify these options, the assembler and
     linker will create larger object and executable files and will
     also be slower.  You will not be able to use `gprof' on all
     systems if you specify this option and you may have problems with
     debugging if you specify both this option and `-g'.

`-fbranch-target-load-optimize'
     Perform branch target register load optimization before prologue /
     epilogue threading.  The use of target registers can typically be
     exposed only during reload, thus hoisting loads out of loops and
     doing inter-block scheduling needs a separate optimization pass.

`-fbranch-target-load-optimize2'
     Perform branch target register load optimization after prologue /
     epilogue threading.

`-fbtr-bb-exclusive'
     When performing branch target register load optimization, don't
     reuse branch target registers in within any basic block.

`-fstack-protector'
     Emit extra code to check for buffer overflows, such as stack
     smashing attacks.  This is done by adding a guard variable to
     functions with vulnerable objects.  This includes functions that
     call alloca, and functions with buffers larger than 8 bytes.  The
     guards are initialized when a function is entered and then checked
     when the function exits.  If a guard check fails, an error message
     is printed and the program exits.

`-fstack-protector-all'
     Like `-fstack-protector' except that all functions are protected.

`-fsection-anchors'
     Try to reduce the number of symbolic address calculations by using
     shared \"anchor\" symbols to address nearby objects.  This
     transformation can help to reduce the number of GOT entries and
     GOT accesses on some targets.

     For example, the implementation of the following function `foo':

          static int a, b, c;
          int foo (void) { return a + b + c; }

     would usually calculate the addresses of all three variables, but
     if you compile it with `-fsection-anchors', it will access the
     variables from a common anchor point instead.  The effect is
     similar to the following pseudocode (which isn't valid C):

          int foo (void)
          {
            register int *xr = &x;
            return xr[&a - &x] + xr[&b - &x] + xr[&c - &x];
          }

     Not all targets support this option.

`--param NAME=VALUE'
     In some places, GCC uses various constants to control the amount of
     optimization that is done.  For example, GCC will not inline
     functions that contain more that a certain number of instructions.
     You can control some of these constants on the command-line using
     the `--param' option.

     The names of specific parameters, and the meaning of the values,
     are tied to the internals of the compiler, and are subject to
     change without notice in future releases.

     In each case, the VALUE is an integer.  The allowable choices for
     NAME are given in the following table:

    `salias-max-implicit-fields'
          The maximum number of fields in a variable without direct
          structure accesses for which structure aliasing will consider
          trying to track each field.  The default is 5

    `salias-max-array-elements'
          The maximum number of elements an array can have and its
          elements still be tracked individually by structure aliasing.
          The default is 4

    `sra-max-structure-size'
          The maximum structure size, in bytes, at which the scalar
          replacement of aggregates (SRA) optimization will perform
          block copies.  The default value, 0, implies that GCC will
          select the most appropriate size itself.

    `sra-field-structure-ratio'
          The threshold ratio (as a percentage) between instantiated
          fields and the complete structure size.  We say that if the
          ratio of the number of bytes in instantiated fields to the
          number of bytes in the complete structure exceeds this
          parameter, then block copies are not used.  The default is 75.

    `max-crossjump-edges'
          The maximum number of incoming edges to consider for
          crossjumping.  The algorithm used by `-fcrossjumping' is
          O(N^2) in the number of edges incoming to each block.
          Increasing values mean more aggressive optimization, making
          the compile time increase with probably small improvement in
          executable size.

    `min-crossjump-insns'
          The minimum number of instructions which must be matched at
          the end of two blocks before crossjumping will be performed
          on them.  This value is ignored in the case where all
          instructions in the block being crossjumped from are matched.
          The default value is 5.

    `max-grow-copy-bb-insns'
          The maximum code size expansion factor when copying basic
          blocks instead of jumping.  The expansion is relative to a
          jump instruction.  The default value is 8.

    `max-goto-duplication-insns'
          The maximum number of instructions to duplicate to a block
          that jumps to a computed goto.  To avoid O(N^2) behavior in a
          number of passes, GCC factors computed gotos early in the
          compilation process, and unfactors them as late as possible.
          Only computed jumps at the end of a basic blocks with no more
          than max-goto-duplication-insns are unfactored.  The default
          value is 8.

    `max-delay-slot-insn-search'
          The maximum number of instructions to consider when looking
          for an instruction to fill a delay slot.  If more than this
          arbitrary number of instructions is searched, the time
          savings from filling the delay slot will be minimal so stop
          searching.  Increasing values mean more aggressive
          optimization, making the compile time increase with probably
          small improvement in executable run time.

    `max-delay-slot-live-search'
          When trying to fill delay slots, the maximum number of
          instructions to consider when searching for a block with
          valid live register information.  Increasing this arbitrarily
          chosen value means more aggressive optimization, increasing
          the compile time.  This parameter should be removed when the
          delay slot code is rewritten to maintain the control-flow
          graph.

    `max-gcse-memory'
          The approximate maximum amount of memory that will be
          allocated in order to perform the global common subexpression
          elimination optimization.  If more memory than specified is
          required, the optimization will not be done.

    `max-gcse-passes'
          The maximum number of passes of GCSE to run.  The default is
          1.

    `max-pending-list-length'
          The maximum number of pending dependencies scheduling will
          allow before flushing the current state and starting over.
          Large functions with few branches or calls can create
          excessively large lists which needlessly consume memory and
          resources.

    `max-inline-insns-single'
          Several parameters control the tree inliner used in gcc.
          This number sets the maximum number of instructions (counted
          in GCC's internal representation) in a single function that
          the tree inliner will consider for inlining.  This only
          affects functions declared inline and methods implemented in
          a class declaration (C++).  The default value is 450.

    `max-inline-insns-auto'
          When you use `-finline-functions' (included in `-O3'), a lot
          of functions that would otherwise not be considered for
          inlining by the compiler will be investigated.  To those
          functions, a different (more restrictive) limit compared to
          functions declared inline can be applied.  The default value
          is 90.

    `large-function-insns'
          The limit specifying really large functions.  For functions
          larger than this limit after inlining inlining is constrained
          by `--param large-function-growth'.  This parameter is useful
          primarily to avoid extreme compilation time caused by
          non-linear algorithms used by the backend.  This parameter is
          ignored when `-funit-at-a-time' is not used.  The default
          value is 2700.

    `large-function-growth'
          Specifies maximal growth of large function caused by inlining
          in percents.  This parameter is ignored when
          `-funit-at-a-time' is not used.  The default value is 100
          which limits large function growth to 2.0 times the original
          size.

    `large-unit-insns'
          The limit specifying large translation unit.  Growth caused
          by inlining of units larger than this limit is limited by
          `--param inline-unit-growth'.  For small units this might be
          too tight (consider unit consisting of function A that is
          inline and B that just calls A three time.  If B is small
          relative to A, the growth of unit is 300\\% and yet such
          inlining is very sane.  For very large units consisting of
          small inlininable functions however the overall unit growth
          limit is needed to avoid exponential explosion of code size.
          Thus for smaller units, the size is increased to `--param
          large-unit-insns' before applying `--param
          inline-unit-growth'.  The default is 10000

    `inline-unit-growth'
          Specifies maximal overall growth of the compilation unit
          caused by inlining.  This parameter is ignored when
          `-funit-at-a-time' is not used.  The default value is 50
          which limits unit growth to 1.5 times the original size.

    `large-stack-frame'
          The limit specifying large stack frames.  While inlining the
          algorithm is trying to not grow past this limit too much.
          Default value is 256 bytes.

    `large-stack-frame-growth'
          Specifies maximal growth of large stack frames caused by
          inlining in percents.  The default value is 1000 which limits
          large stack frame growth to 11 times the original size.

    `max-inline-insns-recursive'
    `max-inline-insns-recursive-auto'
          Specifies maximum number of instructions out-of-line copy of
          self recursive inline function can grow into by performing
          recursive inlining.

          For functions declared inline `--param
          max-inline-insns-recursive' is taken into account.  For
          function not declared inline, recursive inlining happens only
          when `-finline-functions' (included in `-O3') is enabled and
          `--param max-inline-insns-recursive-auto' is used.  The
          default value is 450.

    `max-inline-recursive-depth'
    `max-inline-recursive-depth-auto'
          Specifies maximum recursion depth used by the recursive
          inlining.

          For functions declared inline `--param
          max-inline-recursive-depth' is taken into account.  For
          function not declared inline, recursive inlining happens only
          when `-finline-functions' (included in `-O3') is enabled and
          `--param max-inline-recursive-depth-auto' is used.  The
          default value is 450.

    `min-inline-recursive-probability'
          Recursive inlining is profitable only for function having
          deep recursion in average and can hurt for function having
          little recursion depth by increasing the prologue size or
          complexity of function body to other optimizers.

          When profile feedback is available (see `-fprofile-generate')
          the actual recursion depth can be guessed from probability
          that function will recurse via given call expression.  This
          parameter limits inlining only to call expression whose
          probability exceeds given threshold (in percents).  The
          default value is 10.

    `inline-call-cost'
          Specify cost of call instruction relative to simple
          arithmetics operations (having cost of 1).  Increasing this
          cost disqualifies inlining of non-leaf functions and at the
          same time increases size of leaf function that is believed to
          reduce function size by being inlined.  In effect it
          increases amount of inlining for code having large
          abstraction penalty (many functions that just pass the
          arguments to other functions) and decrease inlining for code
          with low abstraction penalty.  The default value is 16.

    `max-unrolled-insns'
          The maximum number of instructions that a loop should have if
          that loop is unrolled, and if the loop is unrolled, it
          determines how many times the loop code is unrolled.

    `max-average-unrolled-insns'
          The maximum number of instructions biased by probabilities of
          their execution that a loop should have if that loop is
          unrolled, and if the loop is unrolled, it determines how many
          times the loop code is unrolled.

    `max-unroll-times'
          The maximum number of unrollings of a single loop.

    `max-peeled-insns'
          The maximum number of instructions that a loop should have if
          that loop is peeled, and if the loop is peeled, it determines
          how many times the loop code is peeled.

    `max-peel-times'
          The maximum number of peelings of a single loop.

    `max-completely-peeled-insns'
          The maximum number of insns of a completely peeled loop.

    `max-completely-peel-times'
          The maximum number of iterations of a loop to be suitable for
          complete peeling.

    `max-unswitch-insns'
          The maximum number of insns of an unswitched loop.

    `max-unswitch-level'
          The maximum number of branches unswitched in a single loop.

    `lim-expensive'
          The minimum cost of an expensive expression in the loop
          invariant motion.

    `iv-consider-all-candidates-bound'
          Bound on number of candidates for induction variables below
          that all candidates are considered for each use in induction
          variable optimizations.  Only the most relevant candidates
          are considered if there are more candidates, to avoid
          quadratic time complexity.

    `iv-max-considered-uses'
          The induction variable optimizations give up on loops that
          contain more induction variable uses.

    `iv-always-prune-cand-set-bound'
          If number of candidates in the set is smaller than this value,
          we always try to remove unnecessary ivs from the set during
          its optimization when a new iv is added to the set.

    `scev-max-expr-size'
          Bound on size of expressions used in the scalar evolutions
          analyzer.  Large expressions slow the analyzer.

    `vect-max-version-checks'
          The maximum number of runtime checks that can be performed
          when doing loop versioning in the vectorizer.  See option
          ftree-vect-loop-version for more information.

    `max-iterations-to-track'
          The maximum number of iterations of a loop the brute force
          algorithm for analysis of # of iterations of the loop tries
          to evaluate.

    `hot-bb-count-fraction'
          Select fraction of the maximal count of repetitions of basic
          block in program given basic block needs to have to be
          considered hot.

    `hot-bb-frequency-fraction'
          Select fraction of the maximal frequency of executions of
          basic block in function given basic block needs to have to be
          considered hot

    `max-predicted-iterations'
          The maximum number of loop iterations we predict statically.
          This is useful in cases where function contain single loop
          with known bound and other loop with unknown.  We predict the
          known number of iterations correctly, while the unknown
          number of iterations average to roughly 10.  This means that
          the loop without bounds would appear artificially cold
          relative to the other one.

    `tracer-dynamic-coverage'
    `tracer-dynamic-coverage-feedback'
          This value is used to limit superblock formation once the
          given percentage of executed instructions is covered.  This
          limits unnecessary code size expansion.

          The `tracer-dynamic-coverage-feedback' is used only when
          profile feedback is available.  The real profiles (as opposed
          to statically estimated ones) are much less balanced allowing
          the threshold to be larger value.

    `tracer-max-code-growth'
          Stop tail duplication once code growth has reached given
          percentage.  This is rather hokey argument, as most of the
          duplicates will be eliminated later in cross jumping, so it
          may be set to much higher values than is the desired code
          growth.

    `tracer-min-branch-ratio'
          Stop reverse growth when the reverse probability of best edge
          is less than this threshold (in percent).

    `tracer-min-branch-ratio'
    `tracer-min-branch-ratio-feedback'
          Stop forward growth if the best edge do have probability
          lower than this threshold.

          Similarly to `tracer-dynamic-coverage' two values are
          present, one for compilation for profile feedback and one for
          compilation without.  The value for compilation with profile
          feedback needs to be more conservative (higher) in order to
          make tracer effective.

    `max-cse-path-length'
          Maximum number of basic blocks on path that cse considers.
          The default is 10.

    `max-cse-insns'
          The maximum instructions CSE process before flushing. The
          default is 1000.

    `global-var-threshold'
          Counts the number of function calls (N) and the number of
          call-clobbered variables (V).  If NxV is larger than this
          limit, a single artificial variable will be created to
          represent all the call-clobbered variables at function call
          sites.  This artificial variable will then be made to alias
          every call-clobbered variable.  (done as `int * size_t' on
          the host machine; beware overflow).

    `max-aliased-vops'
          Maximum number of virtual operands allowed to represent
          aliases before triggering the alias grouping heuristic.
          Alias grouping reduces compile times and memory consumption
          needed for aliasing at the expense of precision loss in alias
          information.

    `ggc-min-expand'
          GCC uses a garbage collector to manage its own memory
          allocation.  This parameter specifies the minimum percentage
          by which the garbage collector's heap should be allowed to
          expand between collections.  Tuning this may improve
          compilation speed; it has no effect on code generation.

          The default is 30% + 70% * (RAM/1GB) with an upper bound of
          100% when RAM >= 1GB.  If `getrlimit' is available, the
          notion of \"RAM\" is the smallest of actual RAM and
          `RLIMIT_DATA' or `RLIMIT_AS'.  If GCC is not able to
          calculate RAM on a particular platform, the lower bound of
          30% is used.  Setting this parameter and `ggc-min-heapsize'
          to zero causes a full collection to occur at every
          opportunity.  This is extremely slow, but can be useful for
          debugging.

    `ggc-min-heapsize'
          Minimum size of the garbage collector's heap before it begins
          bothering to collect garbage.  The first collection occurs
          after the heap expands by `ggc-min-expand'% beyond
          `ggc-min-heapsize'.  Again, tuning this may improve
          compilation speed, and has no effect on code generation.

          The default is the smaller of RAM/8, RLIMIT_RSS, or a limit
          which tries to ensure that RLIMIT_DATA or RLIMIT_AS are not
          exceeded, but with a lower bound of 4096 (four megabytes) and
          an upper bound of 131072 (128 megabytes).  If GCC is not able
          to calculate RAM on a particular platform, the lower bound is
          used.  Setting this parameter very large effectively disables
          garbage collection.  Setting this parameter and
          `ggc-min-expand' to zero causes a full collection to occur at
          every opportunity.

    `max-reload-search-insns'
          The maximum number of instruction reload should look backward
          for equivalent register.  Increasing values mean more
          aggressive optimization, making the compile time increase
          with probably slightly better performance.  The default value
          is 100.

    `max-cselib-memory-locations'
          The maximum number of memory locations cselib should take
          into account.  Increasing values mean more aggressive
          optimization, making the compile time increase with probably
          slightly better performance.  The default value is 500.

    `max-flow-memory-locations'
          Similar as `max-cselib-memory-locations' but for dataflow
          liveness.  The default value is 100.

    `reorder-blocks-duplicate'
    `reorder-blocks-duplicate-feedback'
          Used by basic block reordering pass to decide whether to use
          unconditional branch or duplicate the code on its
          destination.  Code is duplicated when its estimated size is
          smaller than this value multiplied by the estimated size of
          unconditional jump in the hot spots of the program.

          The `reorder-block-duplicate-feedback' is used only when
          profile feedback is available and may be set to higher values
          than `reorder-block-duplicate' since information about the
          hot spots is more accurate.

    `max-sched-ready-insns'
          The maximum number of instructions ready to be issued the
          scheduler should consider at any given time during the first
          scheduling pass.  Increasing values mean more thorough
          searches, making the compilation time increase with probably
          little benefit.  The default value is 100.

    `max-sched-region-blocks'
          The maximum number of blocks in a region to be considered for
          interblock scheduling.  The default value is 10.

    `max-sched-region-insns'
          The maximum number of insns in a region to be considered for
          interblock scheduling.  The default value is 100.

    `min-spec-prob'
          The minimum probability (in percents) of reaching a source
          block for interblock speculative scheduling.  The default
          value is 40.

    `max-sched-extend-regions-iters'
          The maximum number of iterations through CFG to extend
          regions.  0 - disable region extension, N - do at most N
          iterations.  The default value is 0.

    `max-sched-insn-conflict-delay'
          The maximum conflict delay for an insn to be considered for
          speculative motion.  The default value is 3.

    `sched-spec-prob-cutoff'
          The minimal probability of speculation success (in percents),
          so that speculative insn will be scheduled.  The default
          value is 40.

    `max-last-value-rtl'
          The maximum size measured as number of RTLs that can be
          recorded in an expression in combiner for a pseudo register
          as last known value of that register.  The default is 10000.

    `integer-share-limit'
          Small integer constants can use a shared data structure,
          reducing the compiler's memory usage and increasing its
          speed.  This sets the maximum value of a shared integer
          constant's.  The default value is 256.

    `min-virtual-mappings'
          Specifies the minimum number of virtual mappings in the
          incremental SSA updater that should be registered to trigger
          the virtual mappings heuristic defined by
          virtual-mappings-ratio.  The default value is 100.

    `virtual-mappings-ratio'
          If the number of virtual mappings is virtual-mappings-ratio
          bigger than the number of virtual symbols to be updated, then
          the incremental SSA updater switches to a full update for
          those symbols.  The default ratio is 3.

    `ssp-buffer-size'
          The minimum size of buffers (i.e. arrays) that will receive
          stack smashing protection when `-fstack-protection' is used.

    `max-jump-thread-duplication-stmts'
          Maximum number of statements allowed in a block that needs to
          be duplicated when threading jumps.

    `max-fields-for-field-sensitive'
          Maximum number of fields in a structure we will treat in a
          field sensitive manner during pointer analysis.



"
    end

    artifact 135343 "0README"
      stereotype "document"
      associated_artifacts
      end
      comment "Examine the files

    Makedefs.alpha
    Makedefs.generic
    Makedefs.hp
    Makedefs.ibm
    Makedefs.iris
    Makedefs.linux
    Makedefs.solaris
    Makedefs.sun

and see which one fits your system best; these are samples, and may
not fit any given system exactly. Make any necessary modifications,
then type

    make 'system'

where 'system' is whichver one you chose of

    'alpha', 'generic', 'hp', 'ibm', 'iris', 'linux', 'solaris', or 'sun'

This sets up a symbolic link to the appropriate Makedefs, and
only needs to be done once (per system). Next type

    make clean pnp_funnel

Expect to (possibly) see a warning about the variable 'smp' being used
before it is defined; this is normal.  After that, you should be able
to run pnp_funnel. Two commented sample input files, 'test1.input' and
'test2.input', are provided; you can try running them with the following
commands:

	pnp_funnel < test1.input > your1.output
	pnp_funnel < test2.input > your2.output

Then compare the files 'your1.output' against 'test1.output', and
'your2.output' against 'test2.output'. The data should be exceedingly
similar. For comparison, the file 'comp1.output' contains the output
of another PNP program which solved for exactly the same physical
situation as specified in 'test1.input'. The first run takes about 6
seconds of CPU time on a Pentium-133, and the second about 33 seconds
on the same machine.
"
    end

    artifact 585391 "M_atlas.mk"
      stereotype "document"
      associated_artifacts
      end
      comment "#
# Self Optimising BLAS/LAPACK library 
#
# Set ATLASVERSION to version part of ATLAS directory (if present)
ATLASVERSION?=
# Set ATLASROOTDIR to possible locations for ATLAS
ATLASROOTDIR+=/opt /opt/local /usr /usr/local

#
#  Should not be necessary to alter below here
#

ifndef ATLASROOT
ATLASROOT:=$(strip $(foreach dir_,$(ATLASROOTDIR),$(shell test -d $(dir_)/include/atlas && echo $(dir_))))
endif
ATLASROOTDIR:=

ifeq ($(ATLASROOT),)
ATLAS_INC=$(error \"Atlas library was requested but not found\")
ATLAS_LIB=$(error \"Atlas library was requested but not found\") 
LAPACKLIB=$(error \"Atlas library was requested but not found\")
LAPACKINC=$(error \"Atlas library was requested but not found\")
MATHVER:=$(error \"Atlas library was requested but not found\")
else
ATLAS_INC:=-I$(ATLASROOT)/include/atlas
# ATLASLIB:=$(firstword $(foreach dir_,lib/atlas$(ATLASVERSION) lib,$(shell test -f $(ATLASROOT)/$(dir_)/libatlas.a && echo $(ATLASROOT)/$(dir_))))
ATLASLIB:=-L$(ATLASROOT)/lib
ATLASLIB_STATIC:=$(ATLASROOT)/lib/atlas-base
LAPACKINC:=-DUSE_ATLAS $(ATLAS_INC)
MATHVER:=\"call math_lib_version(libver)\"
ifdef static_build
# Use LAPACK variable for static libs and object files
LAPACKLIB_STATIC:=$(ATLASLIB_STATIC)/liblapack_atlas.a $(ATLASLIB_STATIC)/libf77blas.a $(ATLASLIB_STATIC)/libcblas.a $(ATLASLIB_STATIC)/libatlas.a
else
# Use LAPACKLIB for dynamic libs
LAPACKLIB:=-L$(ATLASLIB) -lblas3gf -llapack3gf
endif
endif


# Local Variables:
# mode: Makefile
# end:"
    end

    artifact 274735 "M_boost.mk"
      stereotype "document"
      associated_artifacts
      end
      comment "# Set BOOSTROOTDIRS to possible locations for Boost
BOOSTROOTDIRS+=/opt/local /usr/local /usr
LIBSUBDIRS=stage/lib intel64 universal em64t lib64 lib
#
#  Should not be necessary to alter below here
#

ifndef BOOSTROOT
BOOSTROOT:=$(strip $(firstword $(foreach dir_,$(BOOSTROOTDIRS),$(shell test -e $(dir_)/boost/version.hpp && echo $(dir_)))))
endif

ifeq ($(BOOSTROOT),)
BOOSTROOT:=$(strip $(firstword $(foreach dir_,$(BOOSTROOTDIRS),$(shell test -e $(dir_)/include/boost/version.hpp && echo $(dir_)))))

ifeq ($(BOOSTROOT),)
BOOST_INC=$(error \"BOOST library was requested but not found 1\")
BOOST_LIB=$(error \"BOOST library was requested but not found 2\")
else
BOOST_INC:=-I$(BOOSTROOT)/include
BOOST_LIB:=$(strip $(foreach dir_,$(LIBSUBDIRS),$(shell test -d $(BOOSTROOT)/$(dir_) && echo -L$(BOOSTROOT)/$(dir_))))
endif

else

BOOST_INC:=$(BOOSTROOT)
BOOST_LIB:=$(strip $(foreach dir_,$(LIBSUBDIRS),$(shell test -d $(BOOSTROOT)/$(dir_) && echo -L$(BOOSTROOT)/$(dir_))))
endif

ifeq ($(BOOST_LIB),-L)
BOOST_LIB:=$(SPACE)
endif

CCCFLAGS+=-I$(BOOST_INC)
LDFLAGS+=$(BOOST_LIB)

# Local Variables:
# mode: Makefile
# end:
"
    end

    artifact 586671 "M_cl.mk"
      stereotype "document"
      associated_artifacts
      end
      comment "##########################################
##  Definitions for Microsoft VC compiler
#########################################
ifndef M_CL_MAK
M_CL_MAK:=1

CCC:=cl
CXX:=cl
AR:=link
ARFLAGS:= /LIB
FORTRAN?=
CPPFLAGS?=
CCFLAGS+=/EHsc /nologo /errorReport:none
CCCFLAGS+=/GR /Gm- /EHsc /Zc:forScope /nologo /errorReport:none

ifeq ($(VARIANT),DEBUG)
OPTFLAGS+=/Od /Zi
LDFLAGS+=/MTd
else
OPTFLAGS+=/O2
LDFLAGS+=/MT
endif

CCFLAGS+=$(OPTFLAGS)
CCCFLAGS+=$(OPTFLAGS)
FORTRANFLAGS?=
LDFLAGS+=$(OPTFLAGS)

FORTRANLIBS?=
OPENMP:=/openmp

endif # end of once-only

#  commands to execute (built-in):
COMPILE.c = $(CC) $(patsubst -%,/%,$(subst -L,/LIBPATH ,$(patsubst -l%,%.lib,$(CFLAGS) $(CPPFLAGS) $(TARGET_ARCH)))) /c /Fo
COMPILE.cc = $(CXX) $(patsubst -%,/%,$(subst -L,/LIBPATH ,$(patsubst -l%,%.lib,$(CXXFLAGS) $(CPPFLAGS) $(TARGET_ARCH)))) /c /Fo
define _makeobj_
%$$(sufobj): %$(1) ; $$(COMPILE$(1))$$@ $$<
endef

$(foreach suff,.c .cc .cpp .cxx .f .F,$(eval $(call _makeobj_,$(suff))))

# Commands to create dummy make dependency files.
# (Or use depend generator such as X11 makedepend
# or Digital Mars makedep or makedep.py)
# %$(sufdep): %$(1)
# 	start makedep.py $$@ $$< $(CC) /showInclude /Zs /nologo $(CPPFLAGS) $(CXXFLAGS)
define _makedep_
%$(sufdep): %$(1) ; @echo # Dummy file > $$@
endef

$(foreach suff,.c .C .cc .cpp .cxx,$(eval $(call _makedep_,$(suff))))

_makeobj_:=
_makedep_:=

define do_link_exe
$(1) : $(2) ; $$(LINK.cpp) $$(LOADLIBES) $$(LDLIBS) /Fe$(1) $(2)
endef

define do_link_shr
$(1) : CCFLAGS+=$(SHRFLAGS)
$(1) : CCCFLAGS+=$(SHRFLAGS)
$(1) : $(2) ; $$(LINK.cpp) $$(LOADLIBES) $$(LDLIBS) /LD /Fe$(1) $(2)
endef

define do_archive
$(1): $(2) ; $$(AR) $$(ARFLAGS) /OUT:$(1) $(2)
endef


# Local Variables:
# mode: Makefile
# end:"
    end

    artifact 585519 "M_cula.mk"
      stereotype "document"
      associated_artifacts
      end
      comment "#
## CULA BLAS/LAPACK library 
#
## Set CULAVERSION to version part of CULA directory (if present)
CULAVERSION?=
# Set CULAROOTDIR to possible locations for CULA
CULAROOTDIR+=/opt /opt/local /usr /usr/local
#
#
#  Should not be necessary to alter below here
#
ifndef CULAROOT
CULAROOT=$(strip $(foreach dir_,$(CULAROOTDIR),$(shell test -f $(dir_)/cula/include/cula.h && echo $(dir_)/cula)))
endif
#
ifeq ($(CULAROOT),)
CULA_INC=$(error \"CULA was requested but not found\")
CULA_LIB=$(error \"CULA was requested but not found\") 
LAPACKINC=$(error \"CULA was requested but not found\")
LAPACKLIB=$(error \"CULA was requested but not found\")
MATHVER=$(error \"CULA was requested but not found\")
else
CULA_INC:=$(foreach dir,$(CULAROOT),-I$(dir)/include)
CULA_LIB:=$(foreach dir,$(CULAROOT),-L$(dir)/lib -L$(dir)/lib64) 
LAPACKLIB:=$(CULA_LIB) -lcula_core -lcula_lapack -lcublas -lcula_lapack_link -lcudart
LAPACKINC:=-DUSE_CULA $(CULA_INC)
MATHVER:=\"call math_lib_version(libver)\"
endif

# Local Variables:
# mode: Makefile
# end:"
    end

    artifact 586799 "M_gcc.mk"
      stereotype "document"
      associated_artifacts
      end
      comment "####################################
##  Definitions for GNU g++ compiler
####################################
ifndef M_GCC_MAK
M_GCC_MAK:=1

#
# Configure where your GCC compilers are
#
# set GCCVER to version part of gcc name (if present)
# (Here is minimum required version)
GCCVER?=-4.4
# Set GCCROOTDIR to possible locations for GCC
GCCROOTDIR+=/opt/bin /opt/local/bin /usr/bin /usr/local/bin
# you can also set GCCROOT to empty if in path
# GCCROOT:=

#
#  Should not be necessary to alter below here
#
ifndef GCCROOT
GCCROOT:=$(strip $(firstword $(foreach dir_,$(GCCROOTDIR),$(shell test -f $(dir_)/gcc$(GCCVER) && echo $(dir_)))))
GFCROOT:=$(strip $(firstword $(foreach dir_,$(GCCROOTDIR),$(shell test -f $(dir_)/gfortran$(GCCVER) && echo $(dir_)))))
endif
GCCROOTDIR:=

##
## Define compiler variables once only.
## 
CC?=$(GCCROOT:=/)gcc$(GCCVER) -m64
CCC?=$(GCCROOT:=/)g++$(GCCVER) -m64
CXX=$(CCC)
FORTRAN?=$(GFCROOT:=/)gfortran$(GCCVER) -m64
CPPFLAGS?=

# compiler version information
CCVERSION:=$(shell $(CCC) -dumpversion)
CCTARGET:=$(shell $(CCC) -dumpmachine)
FCVERSION:=$(shell $(FORTRAN) -dumpversion)
FCTARGET:=$(shell $(FORTRAN) -dumpmachine)

BASE_FLAGS:=-Wall -ggdb -gdwarf-2 -pipe -fmessage-length=0 -ftrapping-math

# --------------------------------------------------
#
# User selected variant
#
# --------------------------------------------------
ifeq ($(VARIANT),DEBUG)
BASE_FLAGS+=-O0 -DDEBUG=1
CCFLAGS+=-pedantic
CCCFLAGS+=
#-Weffc++
FORTRANFLAGS+= -fno-automatic -ffpe-trap=invalid,zero -fbounds-check -Wconversion -mieee-fp -fbounds-check
else
BASE_FLAGS+=-O2 -march=native -DDEBUG=0 -fno-common -funroll-loops -finline -finline-limit=600 -fno-math-errno -fprefetch-loop-arrays -finline-functions -mtune=generic $(GNUOPTFLAGS)
FORTRANFLAGS+= -ffpe-trap=invalid,zero

# --------------------------------------------------
#
# x86 arch SSE flags in non-debug
#
# --------------------------------------------------
ifndef bad_mmx_register
MFPMATH=-mfpmath=sse,387 $(SSEFLAGS)
else
MFPMATH=-mfpmath=sse $(SSEFLAGS)
endif

TEST:=$(shell gcc -dM -E -xc /dev/null)

BASE_FLAGS+=$(if $(findstring __SSE_MATH__,$(TEST)),$(MFPMATH))
SSEFLAGS:=$(if $(findstring __MMX__,$(TEST)),-mmmx)
SSEFLAGS:=$(if $(findstring __SSE__,$(TEST)),-msse)
SSEFLAGS:=$(if $(findstring __SSE2__,$(TEST)),-msse2)
TEST:=$(shell cat /proc/cpuinfo)
SSEFLAGS:=$(if $(findstring sse3,$(TEST)),-msse3)
SSEFLAGS:=$(if $(findstring sse3,$(TEST)),-mssse3)
SSEFLAGS:=$(if $(findstring sse4_1,$(TEST)),-msse4.1)
SSEFLAGS:=$(if $(findstring sse4_2,$(TEST)),-msse4.2)
BASE_FLAGS+=$(SSEFLAGS)
TEST:=

#
# Unscientific floating-math optimisations
#
DEATH= -ffast-math -floop-interchange -floop-block -floop-strip-mine -ftree-loop-distribution -fgcse-sm -fgcse-las -funsafe-loop-optimizations -Wunsafe-loop-optimizations

endif

CCFLAGS+= $(BASE_FLAGS) -Wno-format -Wno-trigraphs 
CCCFLAGS+= $(BASE_FLAGS) -Wno-format -fvisibility-inlines-hidden -Wno-trigraphs 
FORTRANFLAGS+= $(BASE_FLAGS) -fmodulo-sched

# --------------------------------------------------
#
# Compiler version settings
#
# --------------------------------------------------
CCCFLAGS+= -std=c++11 -DHAVE_LLRINT=1 -DHAVE_UNIQPTR=1 -DHAVE_LRINT=1
FORTRANFLAGS+= -cpp -Warray-temporaries -std=f2003 -fall-intrinsics -Wunderflow -fexternal-blas
# -ftree-vectorize
# -flto

LDFLAGS?=
SHRFLAGS?=-fpic

FORTRANLIBS:=-lgfortran


ifndef serial_build
OPENMP:=-fopenmp
else
OPENMP:=
endif

ifdef static_build
LDFLAGS+=-static-libgcc -static-libgfortran ./libstdc++.a
STATIC_DEFSH?=[ -f libstdc++.a ] || ln -s `$(CXX) -print-file-name=libstdc++.a` .
else
ifdef mac_os
SUFLIB=dylib
else
SUFLIB=so
endif
stdc++_lib_dir=$(dir $(shell $(CC) -print-file-name=libstdc++.$(SUFLIB)))
LDFLAGS+=$(foreach dir_,x86_64 .,$(shell test -d $(stdc++_lib_dir)/$(dir_) && echo -L$(stdc++_lib_dir)/$(dir_))) -lstdc++
endif

STATIC_BEGIN=-Wl,\"-(\"
STATIC_END=-Wl,\"-)\"


endif
# END ONCE-ONLY

define _makedep_
%$(sufdep): %$(1)
	set -e; $$(CCC) -MM $$(CPPFLAGS) $(CCCFLAGS) $$< \\
	| sed 's/\\($$*\\)$$(sufobj)[ :]*/\\1$$(sufobj) $$@ : /g' > $$@;\\
	[ -s $$@ ] || rm -f $$@
endef

$(foreach suff,.c .C .cc .cpp .cxx,$(eval $(call _makedep_,$(suff))))
_makedep_:=

ifeq ($(findstring 4.2,$(CCVERSION)),4.2)
define do_link_exe
$(1) : $(2); $$(LINK.cpp) $$(OUTPUT_OPTIONS) -o $(1) $(2)
endef
define do_link_shr
$(1) : CCFLAGS+=$(SHRFLAGS)
$(1) : CCCFLAGS+=$(SHRFLAGS)
$(1) : $(2); $$(LINK.cpp) $$(OUTPUT_OPTIONS) -shared -Wl,-soname,$(1) -o $(1) $(2)
endef
else

define do_link_exe
$(1) : $(2); $$(LINK.cpp) $$(OUTPUT_OPTIONS) -o $(1) -Wl,--start-group $(2) -Wl,--end-group
endef
define do_link_shr
$(1) : CCFLAGS+=$(SHRFLAGS)
$(1) : CCCFLAGS+=$(SHRFLAGS)
$(1) : $(2); $$(LINK.cpp) $$(OUTPUT_OPTIONS) -shared -Wl,-soname,$(1) -o $(1) -Wl,--start-group $(2) -Wl,--end-group
endef
endif

# Local Variables:
# mode: Makefile
# end:
"
    end

    artifact 585775 "M_gsl.mk"
      stereotype "document"
      associated_artifacts
      end
      comment "#
# GNU BLAS/LAPACK library 
#
# Set GSLVERSION to version part of GSL directory (if present)
GSLVERSION?=
# Set GSLROOTDIR to possible locations for GSL
GSLROOTDIR+=/opt /opt/local /usr /usr/local

#
#  Should not be necessary to alter below here
#
ifndef GSLROOT
GSLROOT=$(strip $(foreach dir_,$(GSLROOTDIR),$(shell test -d $(dir_)/include/gsl$(GSLVERSION) && echo $(dir_))))
endif

ifeq ($(GSLROOT),)
GSL_INC=$(error \"GNU Scientific library was requested but not found\")
GSL_LIB=$(error \"GNU Scientific library was requested but not found\") 
LAPACKINC=$(error \"GNU Scientific library was requested but not found\")
LAPACKLIB=$(error \"GNU Scientific library was requested but not found\")
MATHVER=$(error \"GNU Scientific library was requested but not found\")
else
GSL_INC:=$(foreach dir,$(GSLROOT),-I$(dir)/include/gsl$(GSLVERSION))
GSL_LIB:=$(foreach dir,$(GSLROOT),-L$(dir)/lib) 
LAPACKLIB:=$(GSL_LIB) -lgsl -llapack
LAPACKINC:=-DUSE_GSL $(GSL_INC)
MATHVER:=\"call math_lib_version(libver)\"
endif

# Local Variables:
# mode: Makefile
# end:
"
    end

    artifact 585903 "M_intel.mk"
      stereotype "document"
      associated_artifacts
      end
      comment "#
# Compiler definitions
#
# set INTELVER to version part of icc name, usually blank
INTELVER?=
# Set INTELROOTDIR to possible locations for INTEL
INTELROOTDIR+=/opt/bin /opt/local/bin /usr/bin /usr/local/bin
# you can also set INTELROOT to empty if in path
# INTELROOT:=

#
#  Should not be necessary to alter below here
#
ifndef INTELROOT
INTELROOT:=$(strip $(foreach dir_,$(INTELROOTDIR),$(shell test -f $(dir_)/icc$(INTELVER) && echo $(dir_))))
endif
INTELROOTDIR:=
# -m64
#
# Compiler characteristics
# use -DHAVE_LLRINT=1 if you get \"error: function llrint(double) already declared\"
# use -DHAVE_UNIQPTR=1 if std::unique_ptr is available
CXXFLAGS+=-DHAVE_LLRINT=1

#
# Should not need to change below here
#
CC=$(INTELROOT:=/)icc$(INTELVER)
CXX=$(INTELROOT:=/)icpc$(INTELVER)
CCVERSION=$(CXX)$(shell $(CXX) --version)
CCTARGET=$(shell $(CXX) -dumpmachine)
FC=$(INTELROOT:=/)ifort$(INTELVER)
FCVERSION=$(FC)$(shell $(FC) --version)
FCTARGET=$(shell $(FC) -dumpmachine)

BASE_FLAGS:=-fp-model strict -fp-model except 

ifeq ($(VARIANT),DEBUG)

BASE_FLAGS:=-g -gdwarf-2 -O0
FORTRANFLAGS+=-fpp -check bounds -check uninit -ftrapuv

else
# note that Intel's -fast option cannot be used with scientific code.

# set to the optimisation flag for your architecture,
BASE_FLAGS+=-xHost

# x86 SSE arch flags
TEST:=$(shell gcc -dM -E -xc /dev/null)
SSEFLAGS:=$(if $(findstring __SSE2__,$(TEST)),-axSSE2)
SSEFLAGS:=$(if $(findstring __SSE3__,$(TEST)),-axSSE3)
SSEFLAGS:=$(if $(findstring __SSSE3__,$(TEST)),-axSSSE3)
SSEFLAGS:=$(if $(findstring __SSE4.1__,$(TEST)),-axSSE4.1)
TEST:=

BASE_FLAGS+=$(SSEFLAGS) -g -gdwarf-2 -O2 -fpp -no-ansi-alias -unroll -mkl=sequential -mp1 -ipo
endif

OBJ+=*__genmod.f90 *__genmod.mod

CCFLAGS=$(BASE_FLAGS) -Wall
CCCFLAGS=$(BASE_FLAGS) -Wall
FORTRANFLAGS=$(BASE_FLAGS) -warn all
# -pad

ifndef serial_build
OPENMP:=-openmp
else
OPENMP:=
endif

ifdef static_build
LDFLAGS+=-cxxlib
else
LDFLAGS+=-shared-intel -shared-libgcc -cxxlib
endif


STATIC_BEGIN=
STATIC_END=

# Local Variables:
# mode: Makefile
# end:
"
    end

    artifact 586159 "M_local.tmpl"
      stereotype "document"
      associated_artifacts
      end
      comment "ifndef M_LOCAL_MAK
M_LOCAL_MAK:=1

# User set variables
MPI_INC?=/usr/local/openmpi/include
MPI_LIB?=/usr/local/openmpi/lib64
BOOST_INC?=${BOOST_INCLUDEDIR}
BOOST_LIB?=${BOOST_LIBRARYDIR}

# ------------------------------------------------------------
# Select compiler suite to use:
#
# Value causes include of suite specific makefile M_$(COMP).mk
#
# Supplied options are gcc or intel.
COMP=gcc
# Compiler specific options
# GCCVER=-X.X

# ------------------------------------------------------------
#
# MAKEFILE TO TUNE BUILD SYSTEM TO LOCAL MACHINE
#
# Changes here should be for adjusting build to different
# library and compiler versions

# Set some text to var to get static binary
# static_build:=true

# 
# XXVERSION is used to select library version to use
# 
# XXXROOTDIR is a list of directories to search for the
#   the installation location of the library
# 
# NOTE: in XXX.mak XXXVERSION is set using ?= while
# XXXROOTDIR is set using +=
# 
# GOOD PRACTICE IS SET ONLY WHEN NECESSARY

# ------------------------------------------------------------
# Machine/OS specific LD options
# LDHOST= -headerpad_max_install_names -dead_strip

# Settings for MPI library location. 
# MPI_LIB=
# MPI_INC=$(MPI_LIB)/../include


# ------------------------------------------------------------
# Reset flags to be set in the following makefiles
RANDFLAGS= 
LAPACKINC= 
LAPACKLIB_STATIC= 
LAPACKLIB= 

# ------------------------------------------------------------
# The following must be called after the above definitions.
# ------------------------------------------------------------

# Include boost
-include $(ROOTDIR)$(or $(SLASH),/)M_boost.mk


# ------------------------------------------------------------
# Library versions and (likely) locations
#
# Select maths library specific makefile
#
# Intel Math Kernel Library
# MKLVERSION:=10.2.1.017
# MKLROOTDIR:=
-include $(ROOTDIR)$(or $(SLASH),/)M_mkl.mk

# ATLAS math library
# ATLASVERSION:=
# ATLASROOTDIR:=
# set following if atlas libraries have a name suffix eg '_atlas'
#ATLAS_SUFFIX:=
#-include $(ROOTDIR)$(or $(SLASH),/)M_atlas.mk

# GNU BLAS/LAPACK library 
# GSLVERSION:=
# GSLROOTDIR:=
#-include $(ROOTDIR)$(or $(SLASH),/)M_gsl.mk

# ------------------------------------------------------------
# Select random number library (SFMT or dSFMT)
# Default is C++ standard std::tr1::mersenne_twister
# Uncomment is SFMT/dSFMT is preferred and available.
#
# -include $(ROOTDIR)$(or $(SLASH),/)M_sfmt.mk

endif

# Local Variables:
# mode: Makefile
# end:
"
    end

    artifact 586287 "M_mkl.mk"
      stereotype "document"
      associated_artifacts
      end
      comment "#
# Intel Maths Kernel: BLAS/LAPACK library 
#
# Set MKLVERSION to version part of MKL directory (if present)
MKLVERSION?=

# test for absence of MKL_LIB
ifeq ($(MKL_LIB),)
# Set MKLROOTDIR to possible locations for MKL
MKLROOTDIRS+=/opt/intel/mkl/$(MKLVERSION) /usr/local/intel/Frameworks/mkl

#
#  Should not be necessary to alter below here
#

ifndef MKLROOT
MKLROOT:=$(strip $(firstword $(foreach dir_,$(MKLROOTDIRS),$(shell test -e $(dir_)/include/mkl.h && echo $(dir_)))))
endif
else
# Assume if MKL_LIB set, then root is the parent directory.
MKLROOT:=$(dir $(MKL_LIB))
endif

ifeq ($(MKLROOT),)
MKL_INC=$(error \"Intel Maths library was requested but not found\")
MKL_LIB=$(error \"Intel Maths library was requested but not found\")
LAPACKLIB=$(error \"Intel Maths library was requested but not found\")
LAPACKINC=$(error \"Intel Maths library was requested but not found\")
MATHVER=$(error \"Intel Maths library was requested but not found\")
else
ifeq ($(MKL_INC),)
MKL_INC:=$(MKLROOT)/include
endif
ifeq ($(MKL_LIB),)
LIBSUBDIRS=intel64 universal em64t
MKL_LIB:=$(strip $(foreach dir_,$(LIBSUBDIRS),$(shell test -d $(MKLROOT)/lib/$(dir_) && echo $(MKLROOT)/lib/$(dir_))))
endif

LAPACKINC:=-DUSE_MKL -I$(MKL_INC)
LAPACKLIB:=-L$(MKL_LIB) -lmkl_intel_lp64 -lmkl_core -lmkl_sequential
MKLROOT_STATIC:=$(strip $(firstword $(foreach dir_,universal em64t x86_64,$(shell test -e $(MKLROOT)/lib/$(dir_)/libmkl_core.a && echo $(dir_)))))
LAPACKLIB_STATIC:= $(MKLROOT)/lib/$(MKLROOT_STATIC)/libmkl_intel_lp64.a $(MKLROOT)/lib/$(MKLROOT_STATIC)/libmkl_core.a  $(MKLROOT)/lib/$(MKLROOT_STATIC)/libmkl_sequential.a
#LAPACKLIB_STATIC:= $(MKLROOT)/lib/$(MKLROOT_STATIC)/libmkl_intel_lp64.a $(MKLROOT)/lib/$(MKLROOT_STATIC)/libmkl_core.a  $(MKLROOT)/lib/$(MKLROOT_STATIC)/libmkl_intel_thread.a -lpthread
MATHVER:=\"call mkl_get_version_string(libver)\"
endif

# Local Variables:
# mode: Makefile
# end:

"
    end

    artifact 586543 "M_sys.mk"
      stereotype "document"
      associated_artifacts
      end
      comment "#
# M_sys.mk
#
##################################
# Settings for current environment
##################################

OS ?= unix
ifeq ($(origin COMP),default)
COMP = gcc
endif
VARIANT ?= DEBUG

# Preprocessor flags (defines and include directories)
#  CPPFLAGS
# C language flags
#  CCFLAGS
# C++ language flags
#  CCCFLAGS
# Fortran language flags
#  FORTRANFLAGS
# Linker flags
#  LDFLAGS

# Optimisation/debugging flags
# are added depending on VARIANT

##########################
## Include compiler and OS
##########################
-include $(ROOTDIR)$(or $(SLASH),/)M_local.mk
include $(ROOTDIR)$(or $(SLASH),/)M_$(OS).mk
include $(ROOTDIR)$(or $(SLASH),/)M_$(COMP).mk

##############
## Unify Vars
##############
CFLAGS = $(CCFLAGS)
CXXFLAGS = $(CCCFLAGS)
FFLAGS = $(FORTRANFLAGS)
FC = $(FORTRAN)

#############################################
##  Define standard directory descent targets
#############################################
export
unexport dirs

all:: ; $(call doit,all,$(dirs))

install:: ; $(call doit,install,$(dirs))

run_tests:: ; $(call doit,run_tests,$(dirs))

distclean: doclean
	$(call doit,distclean,$(dirs))
	$(RM) core core.* $(TARGETS) *~ $(if $(sufdep),*$(sufdep))

clean: doclean
	$(call doit,clean,$(dirs))

doclean: 
	$(if $(USEROBJ),$(RM) $(USEROBJ))

#############################
##  Default staging locations
#############################
PREFIX=$(ROOTDIR)$(SLASH)stage
BINDIR?=$(PREFIX)$(SLASH)bin
LIBDIR?=$(PREFIX)$(SLASH)lib
INCDIR?=$(PREFIX)$(SLASH)include
DATADIR?=$(PREFIX)$(SLASH)share
DOCDIR?=$(DATADIR)$(SLASH)doc
MANDIR?=$(DATADIR)$(SLASH)man
HTMLDIR?=$(DATADIR)$(SLASH)html
################################################
##  Example link library setup with alternatives
################################################
##  
##  # Make this a one time only definition
##  
##  ifndef USE_XML_MAK
##  USE_XML_MAK:=1
##  
##  ifdef ($(XMLLIB))
##  ifeq ($(XMLLIB),EXPAT)
##  CPPFLAGS+=-DEXPAT
##  LDFLAGS+=-lexpat
##  endif
##  
##  ifeq ($(XMLLIB),XML2)
##  CPPFLAGS+=-DXML2 `xml2-config --cflags`
##  LDFLAGS+=`xml2-config --libs`
##  endif
##  
##  endif # XMLLIB
##  
##  endif # USE_XML_MAK

# Local Variables:
# mode: Makefile
# end:
"
    end

    artifact 587055 "M_Windows_NT.mk"
      stereotype "document"
      associated_artifacts
      end
      comment "# Definition of for loop in local shell.

define doit
IF \"$(2)\" NEQ \"\" FOR %%W IN ( $(2) ) DO \"$(subst /,\\,$(MAKE))\" -C %%W $(1)
endef

ifndef M_WINNT_MAK
M_WINNT_MAK:=1

# Standard Suffixes
sufobj:=.obj
sufexe:=.exe
sufdep:=.dep
suflib:=.lib
sufshr:=.dll
sufshrlink:=.lib
# Programs
MKDIR?=MD
COPY?=COPY /Y /B /V
RM:=-$(shell echo %COMSPEC%) /C DEL /F

# Path separator
SLASH?=\\\\

# END OF ONCE-ONLY.
endif

define do_install
install:: $(1) ; IF \"\" NEQ \"$$($(2))\" ( ( IF NOT EXIST $(if $(2),$$($(2)),$(3)) ( $$(MKDIR) $(if $(2),$$($(2)),$(3)) ) ) & $$(COPY) $(1) $(if $(2),$$($(2)),$(3))\\$(1) )
endef

# Local Variables:
# mode: Makefile
# end:
"
    end

    artifact 586927 "M_unix.mk"
      stereotype "document"
      associated_artifacts
      end
      comment " # Definition of for loop in local shell.
define doit
$(if $(2),STATUS=0 ; for subdir in $(2); do $(MAKE) -C $${subdir}  $(1) || STATUS=$$? ; done ; exit $${STATUS})
endef

# MAKE MOST VARIABLES ONCE-ONLY
ifndef M_UNIX_MAK
M_UNIX_MAK:=1

# Flags for the install targets.
BINIFLAGS?=-m 755
FILEIFLAGS?=-m 644
INSTALL?=install

# Standard suffixes
sufobj:=.o
sufexe:=
suflib:=.a
sufshr:=.so
sufshrlink:=.so
sufdep:=.d

# Path separator
SLASH?=/

# END OF ONCE-ONLY.
endif

define do_install
install:: $(1) ; $$(INSTALL) -d $(if $(2),$$($(2)),$(3)) ; $$(INSTALL) $$($(if BIN==$(2),BIN,FILE)IFLAGS) $(1) $(if $(2),$$($(2)),$(3))/$(1)
endef

define do_archive
$(1): $(2) ; $$(AR) $$(ARFLAGS) $(1) $(2)
endef

# Local Variables:
# mode: Makefile
# end:
"
    end

    artifact 364719 "COPYRIGHT"
      stereotype "document"
      associated_artifacts
      end
      comment "This code was developed at the German Research School for Simulation
Science (C) 2012 unless otherwise indicated."
    end

    artifact 135471 "CHANGELOG"
      stereotype "document"
      associated_artifacts
      end
      comment "= February 2011 =

Justin Finnerty j.finnerty@grs-sim.de

Rewrote in C++ with XML input file and XML or text output files.

= Date unknown =

PNP made available on-line at  http://www.pnponline.org/

It is a user friendly version of Uwe Hollerbach's one dimensional PNP program and was kindly written by Brice Burgess.

Please let us (Bob Eisenberg: beisenbe@rush.edu Brice Burgess: nesta@iceburg.net) of any criticisms or suggestions you would like to make.

= August 1998 =

Uwe Hollerbach (uhollerbach@norfolk-county.com or
uwe@aix550.phys.rush.edu)

Added ability to use funnels to represent the baths

= June 1998 =

Wolfgang Nonner (wnonner@chroma.med.miami.edu of the Dept of
Biophysics and Physiology at the University of Miami)

Rewrote original code into ANSI C (pre C98 std)

= Before June 1998 =

Duan Chen

Original PNP code with with spatially varying dielectric coefficient, diffusion coefficient, and cross sectional area.
"
    end

    artifact 438959 "Develop.t2t"
      stereotype "document"
      associated_artifacts
      end
      comment "Developers Guide 
pnp_project 
2012

= Introduction =

Origin sources.

+ A Fortran 77 language version from Boda that used the PNP case
as part of a Monte-Carlo simulation of ion-channels.  This is the
base-line for the interface of PNP theory with an atomistic model.

+ A Fortran 2003 language version from Finnerty that refactored the
code of Boda to use modules.  In this process code multiplicity was
eliminated.  The ultimate development of this Fortran code within
the GRS Ion Channel project was 'ionch' release 17.1

= Compilation environment difference management =

Two header files control adaptation to the user's compilation
environment.  The content of these files is split depending
on the type of adaptation required.  The 'config.hpp' file
contains feature macros and helper macros to adapt code to
legacy C/C++ environment.  The 'require.hpp' file contains
code to assist in providing C++2011 features not yet included
by the compiler.

== The 'config.hpp' ==

Note that this file also includes macros that control the
inclusion of debugging and testing code.  These are discussed
in the relevant sections of this document and are not included
here.

== Feature test macros ==

These macros are to be used in user code to select alternative
implementations based on the availability of some feature.  The
user has to manually code the different implementations.  To change
the default value the user should define the macro to 0 or 1
on the compiler command line (ie ``-DHAVE_DEV_RANDOM=1``).

+ HAVE_DEV_RANDOM : default = 0 : If the system has a ``/dev/random``
  file that provides high-quality random numbers.  Code that want to
  use high-quality random numbers can then choose to use data from
  this file or some other alternative.  Note that in my experience
  the number of random numbers per second that can be obtained from
  ``/dev/random`` is very low compared to a good random number
  generation algorithm such as Mersenne Twister.  As such it might
  be best used to obtain seed values for such an algorithm, rather
  than being used directly.

+ HAVE_BACKTRACE : default = 1 : If the C-library provides a
  ``backtrace`` function for examining the current call-stack setting
  this to 1 will make backtrace information available to some of
  the test macros.



== Unifying macros ==

These macros provide a unified way to use features that are
implemented in different ways in different compilers.

+ IONCH_API and IONCH_LOCAL : These macros define the visibility
  of symbols in dynamic libraries.  On Unix the default is to make
  all symbols visible so the developer does not need to do anything
  to generate a working dynamic library.  On other OSs the default
  visibility is to hide all the symbols and the developer is expected
  to explicitly define which symbols to make visible.  When these
  macros are used they explicitly expose (IONCH_API) or hide
  (IONCH_LOCAL) the symbol in the dynamic library regardless of the
  default visibility of the OS.  They are currently unused in the
  project but are provided for possible future development.



== The 'require.hpp' file ==

The code is written with all features of C++2011.
|| C++2011 feature | How implemented ||
| ``auto`` | required, no alternative
| ``nullptr`` | replacement
| ``shared_ptr`` | Use boost version to support serialization.


== Macro mechanism ==

The macro mechanism defines a preprocessor macro that substitutes
an available alternative.  Such alternatives are less safe than the
C++2011 feature which should be used whenever possible.  All these
macros have a feature macro that must be defined if a feature is
_not_ available.

+ nullptr : Feature macro ``NO_CPP2011_NULLPTR``.  Replaced with
  the example workaround class from the C++ standard proposal
  or if __GNUC__ is defined the GCC ``__null`` is used.


== Global typedefs ==

The bouml 'generation settings' allow us to specify which version
of various types to use as a stereotype in automatically generated
code.  To expose the same type in user writen code we provide
meta-function classes in ``Config::Global typedefs`` that are defined
in terms of the bouml 'generation settings' stereotype.  For example
to use the same type that bouml uses for the ``auto_ptr`` stereotype
you would have code such as:

To modify the 'generation settings' for your C++ compiler suite the
following tabs in these settings needs to be checked.  The alternatives are listed in their order of preference.

+ Stereotypes

++ weak_ptr : set to std::weak_ptr or boost::weak_ptr

+ C++[5]::External types : add include files for these types.



= Code division =

The code is divided into a set of packages:

: Application management : Classes that manage the simulation, from
reading in the input files to executing the simulation steps/trials.

: Configuration : Classes that manage the set of particles and
their present positions within the simulation cell.

: Evaluation : Classes that calculate the potential energy changes
during a Monte Carlo step/trial.

: Geometry : Classes that manage the geometric properties of
the simulation cell.

: Sample collection : Classes for collecting sample data from the
simulation and for managing that data.

: Step : Classes for determining and encapsulating the change in
the configuration made in a single trial/step.




= In-code testing =

The design-by-contract pattern is used to help ensure the correctness
and quality of the code.  (for more details of this pattern see
\"Object-Oriented Software Construction\" by Bertrand Meyer)

The system in use in this program consists of several checking
conditionals and an input value conditional.  All have the same
interface of two arguments.  The first argument is a boolean test
conditional that is expected to be true.  The second argument is a
message giving details specific to the failed test.  In addition
the program reports information about the code location of the error
(possibly including a call stack).

The definitions for the macros and support code is in the
``contract_error`` class within the ``Utility (BAL)/program
verification`` class view and the class's corresponding ``contract``
artifact

Checking conditionals that may be optionally compiled into the
program:

: IONCH_ALWAYS : This test is non-optional and should be used to
verify conditions that are dependent on conditions while the progam
is running.  This should be rarely used as it indicates an error
that should have been handled explicitly.  In practice it might may
be used for such things as checking C-library calls succeeded where
you don't want to handle the error cases yourself.

: IONCH_INPUT : Check that runtime inputs to the program (from the
user) are within allowed values.  This is also used to check data
derived from input; for example to check that dividing some length
into intervals gives a number of segments below some limit.  As
input is never controlled by the program this test is always
available.  In addition to the information provided with IONCH_ALWAYS,
this method calls a locally defined input_helper
(std::ostream&,std::string) method.  This method can be used to
create a detailed feedback message describing the expected input
for the entire module or class in addition to the error-specific
message provided in the method call.

: IONCH_REQUIRE : Check the arguments to a method fit within the
method's advertised input domain.  As we do not necessarily completely
know how the method will be called this is usually the last test
to be removed by conditional compilation.

: IONCH_ENSURE : Test the programmer's logic has led to a method's
result within the domain advertised by the method (and so expected
by the method's caller).  It should be used in any non-trivial
method to ensure the method's post-conditions are met.  Ideally if
the method's input is within the advertised domain (as checked by
IONCH_REQUIRE) the results of a well-tested method should always
be correct, so this is conditionally removed before IONCH_REQUIRE
by conditional compilation.

: IONCH_CHECK : Testing the programmer's logic.  This lets the
progammer assert what they think should be true is actually true!
It is intended to allow the programmer to insert a check of
intermediate results during the development of a method.  As a
mainly developement test it is usually the first test to be removed
by conditional compilation.

: IONCH_INDEX : Variant of IONCH_CHECK for testing an index value
is within some [0,X) range.

: IONCH_RANGE : Variant of IONCH_CHECK for testing a value value
is within some [X,Y] range.

For those c-libraries that provide a means to inspect the current
call stack we use two methods 'backtrace' and 'backtrace_symbols'
to generate a message containing this information.  We use the same
interface as the GNU libc methods.




"
    end

    artifact 364847 "LICENSE.txt"
      stereotype "document"
      associated_artifacts
      end
      comment "                    GNU GENERAL PUBLIC LICENSE
                       Version 3, 29 June 2007

 Copyright (C) 2007 Free Software Foundation, Inc. <http://fsf.org/>
 Everyone is permitted to copy and distribute verbatim copies
 of this license document, but changing it is not allowed.

                            Preamble

  The GNU General Public License is a free, copyleft license for
software and other kinds of works.

  The licenses for most software and other practical works are designed
to take away your freedom to share and change the works.  By contrast,
the GNU General Public License is intended to guarantee your freedom to
share and change all versions of a program--to make sure it remains free
software for all its users.  We, the Free Software Foundation, use the
GNU General Public License for most of our software; it applies also to
any other work released this way by its authors.  You can apply it to
your programs, too.

  When we speak of free software, we are referring to freedom, not
price.  Our General Public Licenses are designed to make sure that you
have the freedom to distribute copies of free software (and charge for
them if you wish), that you receive source code or can get it if you
want it, that you can change the software or use pieces of it in new
free programs, and that you know you can do these things.

  To protect your rights, we need to prevent others from denying you
these rights or asking you to surrender the rights.  Therefore, you have
certain responsibilities if you distribute copies of the software, or if
you modify it: responsibilities to respect the freedom of others.

  For example, if you distribute copies of such a program, whether
gratis or for a fee, you must pass on to the recipients the same
freedoms that you received.  You must make sure that they, too, receive
or can get the source code.  And you must show them these terms so they
know their rights.

  Developers that use the GNU GPL protect your rights with two steps:
(1) assert copyright on the software, and (2) offer you this License
giving you legal permission to copy, distribute and/or modify it.

  For the developers' and authors' protection, the GPL clearly explains
that there is no warranty for this free software.  For both users' and
authors' sake, the GPL requires that modified versions be marked as
changed, so that their problems will not be attributed erroneously to
authors of previous versions.

  Some devices are designed to deny users access to install or run
modified versions of the software inside them, although the manufacturer
can do so.  This is fundamentally incompatible with the aim of
protecting users' freedom to change the software.  The systematic
pattern of such abuse occurs in the area of products for individuals to
use, which is precisely where it is most unacceptable.  Therefore, we
have designed this version of the GPL to prohibit the practice for those
products.  If such problems arise substantially in other domains, we
stand ready to extend this provision to those domains in future versions
of the GPL, as needed to protect the freedom of users.

  Finally, every program is threatened constantly by software patents.
States should not allow patents to restrict development and use of
software on general-purpose computers, but in those that do, we wish to
avoid the special danger that patents applied to a free program could
make it effectively proprietary.  To prevent this, the GPL assures that
patents cannot be used to render the program non-free.

  The precise terms and conditions for copying, distribution and
modification follow.

                       TERMS AND CONDITIONS

  0. Definitions.

  \"This License\" refers to version 3 of the GNU General Public License.

  \"Copyright\" also means copyright-like laws that apply to other kinds of
works, such as semiconductor masks.

  \"The Program\" refers to any copyrightable work licensed under this
License.  Each licensee is addressed as \"you\".  \"Licensees\" and
\"recipients\" may be individuals or organizations.

  To \"modify\" a work means to copy from or adapt all or part of the work
in a fashion requiring copyright permission, other than the making of an
exact copy.  The resulting work is called a \"modified version\" of the
earlier work or a work \"based on\" the earlier work.

  A \"covered work\" means either the unmodified Program or a work based
on the Program.

  To \"propagate\" a work means to do anything with it that, without
permission, would make you directly or secondarily liable for
infringement under applicable copyright law, except executing it on a
computer or modifying a private copy.  Propagation includes copying,
distribution (with or without modification), making available to the
public, and in some countries other activities as well.

  To \"convey\" a work means any kind of propagation that enables other
parties to make or receive copies.  Mere interaction with a user through
a computer network, with no transfer of a copy, is not conveying.

  An interactive user interface displays \"Appropriate Legal Notices\"
to the extent that it includes a convenient and prominently visible
feature that (1) displays an appropriate copyright notice, and (2)
tells the user that there is no warranty for the work (except to the
extent that warranties are provided), that licensees may convey the
work under this License, and how to view a copy of this License.  If
the interface presents a list of user commands or options, such as a
menu, a prominent item in the list meets this criterion.

  1. Source Code.

  The \"source code\" for a work means the preferred form of the work
for making modifications to it.  \"Object code\" means any non-source
form of a work.

  A \"Standard Interface\" means an interface that either is an official
standard defined by a recognized standards body, or, in the case of
interfaces specified for a particular programming language, one that
is widely used among developers working in that language.

  The \"System Libraries\" of an executable work include anything, other
than the work as a whole, that (a) is included in the normal form of
packaging a Major Component, but which is not part of that Major
Component, and (b) serves only to enable use of the work with that
Major Component, or to implement a Standard Interface for which an
implementation is available to the public in source code form.  A
\"Major Component\", in this context, means a major essential component
(kernel, window system, and so on) of the specific operating system
(if any) on which the executable work runs, or a compiler used to
produce the work, or an object code interpreter used to run it.

  The \"Corresponding Source\" for a work in object code form means all
the source code needed to generate, install, and (for an executable
work) run the object code and to modify the work, including scripts to
control those activities.  However, it does not include the work's
System Libraries, or general-purpose tools or generally available free
programs which are used unmodified in performing those activities but
which are not part of the work.  For example, Corresponding Source
includes interface definition files associated with source files for
the work, and the source code for shared libraries and dynamically
linked subprograms that the work is specifically designed to require,
such as by intimate data communication or control flow between those
subprograms and other parts of the work.

  The Corresponding Source need not include anything that users
can regenerate automatically from other parts of the Corresponding
Source.

  The Corresponding Source for a work in source code form is that
same work.

  2. Basic Permissions.

  All rights granted under this License are granted for the term of
copyright on the Program, and are irrevocable provided the stated
conditions are met.  This License explicitly affirms your unlimited
permission to run the unmodified Program.  The output from running a
covered work is covered by this License only if the output, given its
content, constitutes a covered work.  This License acknowledges your
rights of fair use or other equivalent, as provided by copyright law.

  You may make, run and propagate covered works that you do not
convey, without conditions so long as your license otherwise remains
in force.  You may convey covered works to others for the sole purpose
of having them make modifications exclusively for you, or provide you
with facilities for running those works, provided that you comply with
the terms of this License in conveying all material for which you do
not control copyright.  Those thus making or running the covered works
for you must do so exclusively on your behalf, under your direction
and control, on terms that prohibit them from making any copies of
your copyrighted material outside their relationship with you.

  Conveying under any other circumstances is permitted solely under
the conditions stated below.  Sublicensing is not allowed; section 10
makes it unnecessary.

  3. Protecting Users' Legal Rights From Anti-Circumvention Law.

  No covered work shall be deemed part of an effective technological
measure under any applicable law fulfilling obligations under article
11 of the WIPO copyright treaty adopted on 20 December 1996, or
similar laws prohibiting or restricting circumvention of such
measures.

  When you convey a covered work, you waive any legal power to forbid
circumvention of technological measures to the extent such circumvention
is effected by exercising rights under this License with respect to
the covered work, and you disclaim any intention to limit operation or
modification of the work as a means of enforcing, against the work's
users, your or third parties' legal rights to forbid circumvention of
technological measures.

  4. Conveying Verbatim Copies.

  You may convey verbatim copies of the Program's source code as you
receive it, in any medium, provided that you conspicuously and
appropriately publish on each copy an appropriate copyright notice;
keep intact all notices stating that this License and any
non-permissive terms added in accord with section 7 apply to the code;
keep intact all notices of the absence of any warranty; and give all
recipients a copy of this License along with the Program.

  You may charge any price or no price for each copy that you convey,
and you may offer support or warranty protection for a fee.

  5. Conveying Modified Source Versions.

  You may convey a work based on the Program, or the modifications to
produce it from the Program, in the form of source code under the
terms of section 4, provided that you also meet all of these conditions:

    a) The work must carry prominent notices stating that you modified
    it, and giving a relevant date.

    b) The work must carry prominent notices stating that it is
    released under this License and any conditions added under section
    7.  This requirement modifies the requirement in section 4 to
    \"keep intact all notices\".

    c) You must license the entire work, as a whole, under this
    License to anyone who comes into possession of a copy.  This
    License will therefore apply, along with any applicable section 7
    additional terms, to the whole of the work, and all its parts,
    regardless of how they are packaged.  This License gives no
    permission to license the work in any other way, but it does not
    invalidate such permission if you have separately received it.

    d) If the work has interactive user interfaces, each must display
    Appropriate Legal Notices; however, if the Program has interactive
    interfaces that do not display Appropriate Legal Notices, your
    work need not make them do so.

  A compilation of a covered work with other separate and independent
works, which are not by their nature extensions of the covered work,
and which are not combined with it such as to form a larger program,
in or on a volume of a storage or distribution medium, is called an
\"aggregate\" if the compilation and its resulting copyright are not
used to limit the access or legal rights of the compilation's users
beyond what the individual works permit.  Inclusion of a covered work
in an aggregate does not cause this License to apply to the other
parts of the aggregate.

  6. Conveying Non-Source Forms.

  You may convey a covered work in object code form under the terms
of sections 4 and 5, provided that you also convey the
machine-readable Corresponding Source under the terms of this License,
in one of these ways:

    a) Convey the object code in, or embodied in, a physical product
    (including a physical distribution medium), accompanied by the
    Corresponding Source fixed on a durable physical medium
    customarily used for software interchange.

    b) Convey the object code in, or embodied in, a physical product
    (including a physical distribution medium), accompanied by a
    written offer, valid for at least three years and valid for as
    long as you offer spare parts or customer support for that product
    model, to give anyone who possesses the object code either (1) a
    copy of the Corresponding Source for all the software in the
    product that is covered by this License, on a durable physical
    medium customarily used for software interchange, for a price no
    more than your reasonable cost of physically performing this
    conveying of source, or (2) access to copy the
    Corresponding Source from a network server at no charge.

    c) Convey individual copies of the object code with a copy of the
    written offer to provide the Corresponding Source.  This
    alternative is allowed only occasionally and noncommercially, and
    only if you received the object code with such an offer, in accord
    with subsection 6b.

    d) Convey the object code by offering access from a designated
    place (gratis or for a charge), and offer equivalent access to the
    Corresponding Source in the same way through the same place at no
    further charge.  You need not require recipients to copy the
    Corresponding Source along with the object code.  If the place to
    copy the object code is a network server, the Corresponding Source
    may be on a different server (operated by you or a third party)
    that supports equivalent copying facilities, provided you maintain
    clear directions next to the object code saying where to find the
    Corresponding Source.  Regardless of what server hosts the
    Corresponding Source, you remain obligated to ensure that it is
    available for as long as needed to satisfy these requirements.

    e) Convey the object code using peer-to-peer transmission, provided
    you inform other peers where the object code and Corresponding
    Source of the work are being offered to the general public at no
    charge under subsection 6d.

  A separable portion of the object code, whose source code is excluded
from the Corresponding Source as a System Library, need not be
included in conveying the object code work.

  A \"User Product\" is either (1) a \"consumer product\", which means any
tangible personal property which is normally used for personal, family,
or household purposes, or (2) anything designed or sold for incorporation
into a dwelling.  In determining whether a product is a consumer product,
doubtful cases shall be resolved in favor of coverage.  For a particular
product received by a particular user, \"normally used\" refers to a
typical or common use of that class of product, regardless of the status
of the particular user or of the way in which the particular user
actually uses, or expects or is expected to use, the product.  A product
is a consumer product regardless of whether the product has substantial
commercial, industrial or non-consumer uses, unless such uses represent
the only significant mode of use of the product.

  \"Installation Information\" for a User Product means any methods,
procedures, authorization keys, or other information required to install
and execute modified versions of a covered work in that User Product from
a modified version of its Corresponding Source.  The information must
suffice to ensure that the continued functioning of the modified object
code is in no case prevented or interfered with solely because
modification has been made.

  If you convey an object code work under this section in, or with, or
specifically for use in, a User Product, and the conveying occurs as
part of a transaction in which the right of possession and use of the
User Product is transferred to the recipient in perpetuity or for a
fixed term (regardless of how the transaction is characterized), the
Corresponding Source conveyed under this section must be accompanied
by the Installation Information.  But this requirement does not apply
if neither you nor any third party retains the ability to install
modified object code on the User Product (for example, the work has
been installed in ROM).

  The requirement to provide Installation Information does not include a
requirement to continue to provide support service, warranty, or updates
for a work that has been modified or installed by the recipient, or for
the User Product in which it has been modified or installed.  Access to a
network may be denied when the modification itself materially and
adversely affects the operation of the network or violates the rules and
protocols for communication across the network.

  Corresponding Source conveyed, and Installation Information provided,
in accord with this section must be in a format that is publicly
documented (and with an implementation available to the public in
source code form), and must require no special password or key for
unpacking, reading or copying.

  7. Additional Terms.

  \"Additional permissions\" are terms that supplement the terms of this
License by making exceptions from one or more of its conditions.
Additional permissions that are applicable to the entire Program shall
be treated as though they were included in this License, to the extent
that they are valid under applicable law.  If additional permissions
apply only to part of the Program, that part may be used separately
under those permissions, but the entire Program remains governed by
this License without regard to the additional permissions.

  When you convey a copy of a covered work, you may at your option
remove any additional permissions from that copy, or from any part of
it.  (Additional permissions may be written to require their own
removal in certain cases when you modify the work.)  You may place
additional permissions on material, added by you to a covered work,
for which you have or can give appropriate copyright permission.

  Notwithstanding any other provision of this License, for material you
add to a covered work, you may (if authorized by the copyright holders of
that material) supplement the terms of this License with terms:

    a) Disclaiming warranty or limiting liability differently from the
    terms of sections 15 and 16 of this License; or

    b) Requiring preservation of specified reasonable legal notices or
    author attributions in that material or in the Appropriate Legal
    Notices displayed by works containing it; or

    c) Prohibiting misrepresentation of the origin of that material, or
    requiring that modified versions of such material be marked in
    reasonable ways as different from the original version; or

    d) Limiting the use for publicity purposes of names of licensors or
    authors of the material; or

    e) Declining to grant rights under trademark law for use of some
    trade names, trademarks, or service marks; or

    f) Requiring indemnification of licensors and authors of that
    material by anyone who conveys the material (or modified versions of
    it) with contractual assumptions of liability to the recipient, for
    any liability that these contractual assumptions directly impose on
    those licensors and authors.

  All other non-permissive additional terms are considered \"further
restrictions\" within the meaning of section 10.  If the Program as you
received it, or any part of it, contains a notice stating that it is
governed by this License along with a term that is a further
restriction, you may remove that term.  If a license document contains
a further restriction but permits relicensing or conveying under this
License, you may add to a covered work material governed by the terms
of that license document, provided that the further restriction does
not survive such relicensing or conveying.

  If you add terms to a covered work in accord with this section, you
must place, in the relevant source files, a statement of the
additional terms that apply to those files, or a notice indicating
where to find the applicable terms.

  Additional terms, permissive or non-permissive, may be stated in the
form of a separately written license, or stated as exceptions;
the above requirements apply either way.

  8. Termination.

  You may not propagate or modify a covered work except as expressly
provided under this License.  Any attempt otherwise to propagate or
modify it is void, and will automatically terminate your rights under
this License (including any patent licenses granted under the third
paragraph of section 11).

  However, if you cease all violation of this License, then your
license from a particular copyright holder is reinstated (a)
provisionally, unless and until the copyright holder explicitly and
finally terminates your license, and (b) permanently, if the copyright
holder fails to notify you of the violation by some reasonable means
prior to 60 days after the cessation.

  Moreover, your license from a particular copyright holder is
reinstated permanently if the copyright holder notifies you of the
violation by some reasonable means, this is the first time you have
received notice of violation of this License (for any work) from that
copyright holder, and you cure the violation prior to 30 days after
your receipt of the notice.

  Termination of your rights under this section does not terminate the
licenses of parties who have received copies or rights from you under
this License.  If your rights have been terminated and not permanently
reinstated, you do not qualify to receive new licenses for the same
material under section 10.

  9. Acceptance Not Required for Having Copies.

  You are not required to accept this License in order to receive or
run a copy of the Program.  Ancillary propagation of a covered work
occurring solely as a consequence of using peer-to-peer transmission
to receive a copy likewise does not require acceptance.  However,
nothing other than this License grants you permission to propagate or
modify any covered work.  These actions infringe copyright if you do
not accept this License.  Therefore, by modifying or propagating a
covered work, you indicate your acceptance of this License to do so.

  10. Automatic Licensing of Downstream Recipients.

  Each time you convey a covered work, the recipient automatically
receives a license from the original licensors, to run, modify and
propagate that work, subject to this License.  You are not responsible
for enforcing compliance by third parties with this License.

  An \"entity transaction\" is a transaction transferring control of an
organization, or substantially all assets of one, or subdividing an
organization, or merging organizations.  If propagation of a covered
work results from an entity transaction, each party to that
transaction who receives a copy of the work also receives whatever
licenses to the work the party's predecessor in interest had or could
give under the previous paragraph, plus a right to possession of the
Corresponding Source of the work from the predecessor in interest, if
the predecessor has it or can get it with reasonable efforts.

  You may not impose any further restrictions on the exercise of the
rights granted or affirmed under this License.  For example, you may
not impose a license fee, royalty, or other charge for exercise of
rights granted under this License, and you may not initiate litigation
(including a cross-claim or counterclaim in a lawsuit) alleging that
any patent claim is infringed by making, using, selling, offering for
sale, or importing the Program or any portion of it.

  11. Patents.

  A \"contributor\" is a copyright holder who authorizes use under this
License of the Program or a work on which the Program is based.  The
work thus licensed is called the contributor's \"contributor version\".

  A contributor's \"essential patent claims\" are all patent claims
owned or controlled by the contributor, whether already acquired or
hereafter acquired, that would be infringed by some manner, permitted
by this License, of making, using, or selling its contributor version,
but do not include claims that would be infringed only as a
consequence of further modification of the contributor version.  For
purposes of this definition, \"control\" includes the right to grant
patent sublicenses in a manner consistent with the requirements of
this License.

  Each contributor grants you a non-exclusive, worldwide, royalty-free
patent license under the contributor's essential patent claims, to
make, use, sell, offer for sale, import and otherwise run, modify and
propagate the contents of its contributor version.

  In the following three paragraphs, a \"patent license\" is any express
agreement or commitment, however denominated, not to enforce a patent
(such as an express permission to practice a patent or covenant not to
sue for patent infringement).  To \"grant\" such a patent license to a
party means to make such an agreement or commitment not to enforce a
patent against the party.

  If you convey a covered work, knowingly relying on a patent license,
and the Corresponding Source of the work is not available for anyone
to copy, free of charge and under the terms of this License, through a
publicly available network server or other readily accessible means,
then you must either (1) cause the Corresponding Source to be so
available, or (2) arrange to deprive yourself of the benefit of the
patent license for this particular work, or (3) arrange, in a manner
consistent with the requirements of this License, to extend the patent
license to downstream recipients.  \"Knowingly relying\" means you have
actual knowledge that, but for the patent license, your conveying the
covered work in a country, or your recipient's use of the covered work
in a country, would infringe one or more identifiable patents in that
country that you have reason to believe are valid.

  If, pursuant to or in connection with a single transaction or
arrangement, you convey, or propagate by procuring conveyance of, a
covered work, and grant a patent license to some of the parties
receiving the covered work authorizing them to use, propagate, modify
or convey a specific copy of the covered work, then the patent license
you grant is automatically extended to all recipients of the covered
work and works based on it.

  A patent license is \"discriminatory\" if it does not include within
the scope of its coverage, prohibits the exercise of, or is
conditioned on the non-exercise of one or more of the rights that are
specifically granted under this License.  You may not convey a covered
work if you are a party to an arrangement with a third party that is
in the business of distributing software, under which you make payment
to the third party based on the extent of your activity of conveying
the work, and under which the third party grants, to any of the
parties who would receive the covered work from you, a discriminatory
patent license (a) in connection with copies of the covered work
conveyed by you (or copies made from those copies), or (b) primarily
for and in connection with specific products or compilations that
contain the covered work, unless you entered into that arrangement,
or that patent license was granted, prior to 28 March 2007.

  Nothing in this License shall be construed as excluding or limiting
any implied license or other defenses to infringement that may
otherwise be available to you under applicable patent law.

  12. No Surrender of Others' Freedom.

  If conditions are imposed on you (whether by court order, agreement or
otherwise) that contradict the conditions of this License, they do not
excuse you from the conditions of this License.  If you cannot convey a
covered work so as to satisfy simultaneously your obligations under this
License and any other pertinent obligations, then as a consequence you may
not convey it at all.  For example, if you agree to terms that obligate you
to collect a royalty for further conveying from those to whom you convey
the Program, the only way you could satisfy both those terms and this
License would be to refrain entirely from conveying the Program.

  13. Use with the GNU Affero General Public License.

  Notwithstanding any other provision of this License, you have
permission to link or combine any covered work with a work licensed
under version 3 of the GNU Affero General Public License into a single
combined work, and to convey the resulting work.  The terms of this
License will continue to apply to the part which is the covered work,
but the special requirements of the GNU Affero General Public License,
section 13, concerning interaction through a network will apply to the
combination as such.

  14. Revised Versions of this License.

  The Free Software Foundation may publish revised and/or new versions of
the GNU General Public License from time to time.  Such new versions will
be similar in spirit to the present version, but may differ in detail to
address new problems or concerns.

  Each version is given a distinguishing version number.  If the
Program specifies that a certain numbered version of the GNU General
Public License \"or any later version\" applies to it, you have the
option of following the terms and conditions either of that numbered
version or of any later version published by the Free Software
Foundation.  If the Program does not specify a version number of the
GNU General Public License, you may choose any version ever published
by the Free Software Foundation.

  If the Program specifies that a proxy can decide which future
versions of the GNU General Public License can be used, that proxy's
public statement of acceptance of a version permanently authorizes you
to choose that version for the Program.

  Later license versions may give you additional or different
permissions.  However, no additional obligations are imposed on any
author or copyright holder as a result of your choosing to follow a
later version.

  15. Disclaimer of Warranty.

  THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY
APPLICABLE LAW.  EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT
HOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM \"AS IS\" WITHOUT WARRANTY
OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO,
THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
PURPOSE.  THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM
IS WITH YOU.  SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF
ALL NECESSARY SERVICING, REPAIR OR CORRECTION.

  16. Limitation of Liability.

  IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING
WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS
THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY
GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE
USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF
DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD
PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS),
EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF
SUCH DAMAGES.

  17. Interpretation of Sections 15 and 16.

  If the disclaimer of warranty and limitation of liability provided
above cannot be given local legal effect according to their terms,
reviewing courts shall apply local law that most closely approximates
an absolute waiver of all civil liability in connection with the
Program, unless a warranty or assumption of liability accompanies a
copy of the Program in return for a fee.

                     END OF TERMS AND CONDITIONS

            How to Apply These Terms to Your New Programs

  If you develop a new program, and you want it to be of the greatest
possible use to the public, the best way to achieve this is to make it
free software which everyone can redistribute and change under these terms.

  To do so, attach the following notices to the program.  It is safest
to attach them to the start of each source file to most effectively
state the exclusion of warranty; and each file should have at least
the \"copyright\" line and a pointer to where the full notice is found.

    <one line to give the program's name and a brief idea of what it does.>
    Copyright (C) <year>  <name of author>

    This program is free software: you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.

    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU General Public License for more details.

    You should have received a copy of the GNU General Public License
    along with this program.  If not, see <http://www.gnu.org/licenses/>.

Also add information on how to contact you by electronic and paper mail.

  If the program does terminal interaction, make it output a short
notice like this when it starts in an interactive mode:

    <program>  Copyright (C) <year>  <name of author>
    This program comes with ABSOLUTELY NO WARRANTY; for details type `show w'.
    This is free software, and you are welcome to redistribute it
    under certain conditions; type `show c' for details.

The hypothetical commands `show w' and `show c' should show the appropriate
parts of the General Public License.  Of course, your program's commands
might be different; for a GUI interface, you would use an \"about box\".

  You should also get your employer (if you work as a programmer) or school,
if any, to sign a \"copyright disclaimer\" for the program, if necessary.
For more information on this, and how to apply and follow the GNU GPL, see
<http://www.gnu.org/licenses/>.

  The GNU General Public License does not permit incorporating your program
into proprietary programs.  If your program is a subroutine library, you
may consider it more useful to permit linking proprietary applications with
the library.  If this is what you want to do, use the GNU Lesser General
Public License instead of this License.  But first, please read
<http://www.gnu.org/philosophy/why-not-lgpl.html>.
"
    end

    artifact 525103 "local.tmpl"
      stereotype "document"
      associated_artifacts
      end
      comment "#
# local.jam
#
# External library settings
constant MPI_INC : /usr/local/openmpi/include ;
constant MPI_LIB : /usr/local/openmpi/lib64 ;
constant LAPACKLIB : /opt/intel/mkl/10.2.1.017/lib/emt64 -lmkl_intel_lp64 -lmkl_core -lmkl_sequential ;
constant LAPACKINC : -DUSE_MKL /opt/intel/mkl/10.2.1.017/include ;
constant BOOST_INC : [ os.environ BOOST_INCLUDEDIR ] ;
constant BOOST_LIB :  [ os.environ BOOST_LIBRARYDIR ] ;
#
# Set constants for installation paths
project pnp
	: requirements <cflags>\"-ftemplate-depth=150 -fPIC -DHAVE_LLRINT=1 -DHAVE_UNIQPTR=1 -DHAVE_LRINT=1\" <linkflags>\"-fPIC\" ;
import path ;
path-constant PREFIX : stage ;
constant BINDIR : [ path.join $(PREFIX) bin ] ; # User programs
constant DATADIR : [ path.join $(PREFIX) share ] ; # Static libraries
constant DOCDIR : [ path.join $(DATADIR) doc ] ;
constant HTMLDIR : [ path.join $(DATADIR) html ] ;
constant INCDIR : [ path.join $(PREFIX) include ] ;
constant LIBDIR : [ path.join $(PREFIX) lib ] ; # Shared libraries
constant MANDIR  : [ path.join $(DATADIR) man ] ;

"
    end

    artifact 135599 "Reference"
      stereotype "document"
      associated_artifacts
      end
      comment "These programs were originally used in the paper \"Ion Permeation and Glutamate Residues Linked by Poisson-Nernst Planck Theory in L-Type Calcium Channels\" which is supposed to appear in the Sept. 1998 issue of Biophysical Journal."
    end

    artifact 135727 "Manual.t2t"
      stereotype "document"
      associated_artifacts
      end
      comment "Poisson-Nernst Planck Theory
pnp_project
2011

= Introduction =

The Poisson-Nernst-Planck Theory allows us to determine the free
energy of ionic species diffusing along a 1D axis of known
cross-sectional areas in a continuous medium.

= Objective =

To provide a framework for using the continuum PNP theory with
atomistic modelling.  The framework shall provide mechanisms for
(1) translating the modelled environment between the atomistic model and
the PNP model. (2) translating the PNP computed free energy into the 
atomistic model.

= Source code and algorithm =

== Assumptions ==

+ Orientation: The 1d PNP model is defined as a series of diffusion
fronts along a linear axis.  (in older code referred to as \"x\" with
increasing from left to right)  [Code and documentation will be
refactored to refer to axis as \"z\" with intra-cellular domain being
down and extra-cellular being up and values increasing from down to
up.] External code must coordinate this axis with its own frame of
reference.  In the code \"left\" always refers to lower valued corrdinates

+ Diffusion front shape: Existing code sets front shape as circles.  I
do not know if this is a requirement of the theoretical derivation or
if other shapes are valid. [QUESTION]

+ Pore walls: I assume that x-section area changing linearly
between fronts of different size is a requirement of the theory.

== Introduction ==

This code has been adapted from two major sources. 

+ A C-language version from Uwe Hollerbach and related version from
Nonner.  This version only solved the 1d axis case.  This is the
base-line version for the stand-alone continuum PNP theory.

+ A Fortran-language version from Doda that used the PNP 1d case as
part of a Monte-Carlo simulation.  This is the base-line for the
interface of PNP theory with a atomistic model.


Introductions to these earlier version appear below.  It must be
understood that much of what is discussed is no longer relevant to the
current version.  The documentation of methods and attributes in the
current version attempts to detail the corresponding functions and
variables in these earlier versions.

In this documentation and that of the code we assume that the 1D axis 
increases from left to right. 

=== Introduction to Hollerbach/Nonner versions ca. 1998 ===

These functions let you set up a dynamic workspace adapted to your current
PNP problem (involving a number of ion species and a geometrical grid) and
solve the PNP equations in a given geometry and using given boundary
conditions and PNP parameters. The layout of a pore geometry and the
translation of far-bulk into domain-boundary conditions are not topics of
the PNP solver (they are facilitated by other library modules).

PNP theory is solved here in one dimension, assuming homogeneity in the others.
The metrics of the domain are expressed by an axial coordinate and the
area of the surface of homogeneity that belongs to the axial coordinate.
Exact solutions are obtained for both cylindrical and conical domains (with 
flat or spherically curved surfaces, respectively). Approximate solutions are
obtained for domains that are piecewise cylindrical and conical (an example
is a domain that includes a cylindrical pore proper, tapered atria, and
hemispherical subdomains of the bulks). The PNP solver is given the domain
metrics as an array of axial grid coordinates and the corresponding domain
surface areas; it is otherwise unaware of the shape of the domain, and thus
capable of dealing with arbitrary geometries. Furthermore, it works with
the grid defined by the given axial coordinates. This grid generally will be
non-uniform (with intervals made proportional to domain surface area).

The implemented theory makes provisions to account for two forms of specific
short-range interaction that ions may experience in a PNP domain. (1) binding to
saturable sites (which immobilizes the ion), and (2) non-saturable partitioning
(with potential effects on ion mobility as expressed in the diffusion coefficient).
For instance, form (1) may apply to protons that protonize structural carboxyl
groups, whereas form (2) may apply to alkali cations that interact with an array
of structural carbonyl groups. Form (2) is suitable also for introducing Born
energy variations associated with a non-uniform dielectric permittivity (see below).

Several PNP parameters are allowed to vary along the axial coordinate and need to
be specified as axial profiles (on the grid of the axial coordinate array):

  - area of domain surface (see above)
  - relative dielectric permittivity
  - diffusion coefficients of ions
  - 'partition energies' of ions (standard chemical potentials)
  - structural fixed-charge concentration

Saturable binding also is allowed to vary along the pore axis. This is specified
in a client-provided function that computes 'total' ion concentrations along
the pore from the given 'free' concentrations (a simple equilibrium computation,
since the 'free' concentrations in a stationary flux are constant in time).

The PNP solver treats the bulk boundaries as providing flux-independent ion
concentrations and electric potentials. For PNP domains that extend well into
the bulks, the solver can use the far-bulk values. Other boundary treatments
(like Donnan or Guy-Chapman theory) are possible; then the PNP solver is given
the domain-side boundary values produced by the respective boundary treatment.

The first part of this library sets up PNP domains of two basic geometries:

(1) PNP is set up for a cylindrical domain with flat boundaries to the bulks. The
grid is uniform.

(2) PNP is set up for a domain comprising a cylindrical pore proper, two atria of
variable taper, and two hemispherical subdomains of bulk. The grid is non-uniform,
with a mesh width that increases in proportion to domain area. Domain area is
computed as the area of the spherical surface that intersects the domain axis at
the respective grid node and is normal to the walls of the domain at its edge.
Atrial tapers are defined by client-provided functions that compute wall angle
(with domain axis) for a given array of axis grid nodes.

   
NOTE: geometry builders implicitly invoke build_PNP_ws and init_PNP_var.
      A builder itself may allocate and de-allocate some memory in addition to
      that needed for the PNP workspace.


// ----------------------------------------------------------------------
// IN-CODE TESTING.
//
// The system in use in this program consists of four checking
// conditionals and an input value conditional. All have the same
// interface of two arguments.  The first argument is an if test
// conditional that is expected to be true.  The second argument is a
// message giving details specific to the failed test. In addition the
// program reports information about the code location of the error
// (possibly including a call stack).
//
// Checking conditionals that may be optionally compiled into the
// program:
//
// * IONCH_ALWAYS : This test is non-optional and should be used to
// verify conditions that are dependent on conditions while the progam
// is running.  Ideally it should not be used as it indicates an error
// in code that should have raised an exception for the error itself.
// In practice it might may be used for such things as checking
// C-library calls succeeded where you don't want to handle the error
// cases yourself.
//
// * IONCH_INPUT : Check that runtime inputs to the program (from the
// user) are within allowed values.  This is also used to check data
// derived from input; for example to check that dividing some length
// into intervals gives a number of segments below a program limit.
// As input is never controlled by the program this test is always
// available.  In addition to the information provided with
// IONCH_ALWAYS, this method calls a locally defined input_helper
// (std::ostream&,std::string) method.  This method can be used to
// create a detailed feedback message describing the expected input
// for the entire module or class in addition to the error-specific
// message provided in the method call.
// 
// * IONCH_REQUIRE : Check the arguments to a method fit within the
// method's advertised input domain. As we do not necessarily
// completely know how the method will be called this is usually the
// last test to be removed by conditional compilation.
//
// * IONCH_ENSURE : Test the programmer's logic has led to a method's
// result within the domain advertised by the method (and so expected
// by the method's caller). It should be used in any non-trivial
// method to ensure the method's post-conditions are met. Ideally if
// the method's input is within the advertised domain (as checked by
// IONCH_REQUIRE) the results of a well-tested method should always be
// correct, so this is conditionally removed before IONCH_REQUIRE
// by conditional compilation.
//
// * IONCH_CHECK : Testing the programmer's logic.  This lets the
// progammer assert what they think should be true is actually true!
// It is intended to allow the programmer to insert a check of
// intermediate results during the development of a method. As a
// mainly developement test it is usually the first test to be
// removed by conditional compilation.
//
// For those c-libraries that provide a means to inspect the current
// call stack we use two methods 'backtrace' and 'backtrace_symbols'
// to generate a messag containing this information.  We use the same
// interface as the GNU libc methods.
//
"
    end

    artifact 260527 "Jamrules"
      stereotype "document"
      associated_artifacts
      end
      comment "#
# Default Jamrules
#

if $(UNIX)  { SUFSHR ?= .so ; }
else if $(NT) { SUFSHR ?= .dll ; }

if $(JAM_TOOLSET) { TOOLSET ?= $(JAM_TOOLSET) ; }
TOOLSET ?= GNU ;
VARIANT ?= DEBUG ;

# Attempt to override Jambase to use start/end group linker flags
actions Link bind NEEDLIBS
{
	$(LINK) $(LINKFLAGS) -o $(<) -Wl,--start-group $(UNDEFS) $(>) $(NEEDLIBS) $(LINKLIBS) -Wl,--end-group
}


#############################
##
##  Default install locations
##
#############################
PREFIX = stage ;
BINDIR = $(PREFIX)$(SLASH)bin ;
DATADIR = $(PREFIX)$(SLASH)share ;
DOCDIR = $(DATADIR)$(SLASH)doc ;
HTMLDIR = $(DATADIR)$(SLASH)html ;
INCDIR = $(PREFIX)$(SLASH)include ;
LIBDIR = $(PREFIX)$(SLASH)lib ;
MANDIR = $(DATADIR)$(SLASH)man ;

######################################################
##
##  Example definitions for compiler suite (TOOLSETS)
##  It is possible to add definitions here or in a
##  separate file \"$(TOOLSET).jam\", the NOCARE rule
##  tells jam not to worry if file does not exist.
## 
######################################################
NOCARE $(TOOLSET).jam ;
include $(TOOLSET).jam ;
switch $(TOOLSET)
{
case GNUPORT :
CC = gcc-mp-4.4 ;
C++ = g++-mp-4.4 ;
FORTRAN = gfortran-mp-4.4 ;
LINK = $(C++) ;
CCFLAGS += -Wall -std=c99 ; 
# --param max-inline-insns-single=1800 --param inline-unit-growth=500 --param large-function-growth=900 ;
C++FLAGS += -Wall -std=c++0x  -DHAVE_UNIQUE_PTR ; 
# --param max-inline-insns-single=1800 --param inline-unit-growth=500 --param large-function-growth=900 ;
SHRFLAGS = -fpic ;
switch $(VARIANT)
{
case RELEASE :
  OPTIM = -O2 -march=native -msse2 -DDEBUG=0 ;
case * :
  OPTIM = -O0 -gdwarf-2 -DDEBUG=1 ;
  CCFLAGS += -pedantic ;
  C++FLAGS += ; # -Weffc++ ;
}
FORTRANFLAGS += -Wall -c ;
LINKFLAGS += $(OPTIM) ;
OPENMP = -fopenmp ;
FORTRANLIBS += -lgfortran ;

case GNU :
CC = gcc ;
C++ = g++ ;
FORTRAN = gfortran ;
LINK = $(C++) ;
CCFLAGS += -Wall -std=c99 --param max-inline-insns-single=1800 --param inline-unit-growth=500 --param large-function-growth=900 ;
C++FLAGS += -Wall -std=c++0x --param max-inline-insns-single=1800 --param inline-unit-growth=500 --param large-function-growth=900 ;
SHRFLAGS = -fpic ;
switch $(VARIANT)
{
case RELEASE :
  OPTIM = -O2 -march=native -msse2 -DDEBUG=0 ;
case * :
  OPTIM = -O0 -gdwarf-2 -DDEBUG=1 ;
  CCFLAGS += -pedantic ;
  C++FLAGS += ; # -Weffc++ ;
}
FORTRANFLAGS += -Wall -c ;
LINKFLAGS += $(OPTIM) ;
OPENMP = -fopenmp ;
FORTRANLIBS += -lgfortran ;

case INTEL :
CC = icc ;
C++ = icpc ;
FORTRAN = gfortran ;
LINK = $(C++) ;
CCFLAGS += -Wall  -std=c99 -fp-model precise -fnon-call-exceptions -ansi-alias ;
C++FLAGS += -Wall -std=c++0x -ansi-alias -fp-model precise -fexceptions -fnon-call-exceptions -DHAVE_NO_CSTDINT ;
SHRFLAGS = -fpic ;
switch $(VARIANT)
{
case RELEASE :
  OPTIM = -O2 -xHost -mssse3 -DDEBUG=0  ;
case * :
  OPTIM = -O0 -gdwarf-2 -DDEBUG=1 -no-ip ;
  CCFLAGS += -pedantic ;
  C++FLAGS += ; # -Weffc++ ;
}
FORTRANFLAGS += -Wall -c ;
LINKFLAGS += $(OPTIM) ;
OPENMP = -fopenmp ;
FORTRANLIBS += -lgfortran ;
}

##################################################
##
##  Example of how you might define a set of
##  \"standard\" flags for libraries you use often.
##
##################################################
##
##switch $(GUILIB)
##{
##case GTKMM :
##  CCFLAGS += `pkg-config gtkmm-2.4 --cflags` ;
##  C++FLAGS += `pkg-config gtkmm-2.4 --cflags` ;
##  LINKFLAGS += `pkg-config gtkmm-2.4 --libs` ;
##
##case MOTIF :
##  CCFLAGS += -I/usr/include ;
##  C++FLAGS += -I/usr/include ;
##  LINKFLAGS += -L/usr/lib -lXm -lXp -lXpm -lXmu -lXt -lXext -lX11 ;
##
##case QT3 :
##  CCFLAGS += -I$(QTDIR)/include ;
##  C++FLAGS += -I$(QTDIR)/include ;
##  LINKFLAGS += -L$(QTDIR)/lib -lqt-mt -lXext -lX11 -lm ;
##
##case * :
##}
##

# Set variable for variant-specific build-dir handling
BASE_LOCATE_TARGET = $(BUILDDIR)$(SLASH)$(VARIANT) ;
ALL_LOCATE_TARGET = $(BASE_LOCATE_TARGET) ;

"
    end

    artifact 288047 "variable_map.t2t"
      stereotype "document"
      associated_artifacts
      end
      comment "Map of fortran IONCH variables into MC_sim
Justin Finnerty
February 2011

= Common block translations =

Note that the values in mc_sim and ionch are not necessarily 
identical.  Where they differ is usually to do with splitting
a value into a variable and non-variable part to make it more
general in mc_sim.

Meanings of symbols in tables:
+ --  Variable not used
+ name() Value calculated in named function


== const ==

Physical constants or derived constants

|ionch  |mc_sim
|pi	|constants::pi 
|twopi	|--
|tosi   |constants::to_SI
|u0(4,4) |
|eb(4)  |
|beta	| 1/kT
|dsi	|constants::Angstrom
|mag	|-- Seed value for random number generator
|flags(8) |
|(tsi)	|mc_evalautor.temperature : Absolute temperature 
|(eps0)	|constants::epsilon0
|(ehg)	|constants::e0

== conf ==

The MC particle set

|rx(ntotmx)	|position.x, mc_ion_instance.particles
|ry(ntotmx)	|position.y, mc_ion_instance.particles
|rz(ntotmx)	|position.z, mc_ion_instance.particles
|r2(ntotmx)	|position.r, mc_ion_instance.particles
|indspc(nspcmx,nionmx) | implicit as particles are stored by specie
|rii(ntotmx,ntotmx)    | calculated on the fly
|n(nspcmx)      |mc_ion_instance.size
|ispcbk(ntotmx) |--


== spec ==

The particle type data set

|d(nspcmx)	|mc_ion_instance.radius (==d/2)
|dd(nspcmx,nspcmx) |mc_ion_instance.minimum_distance()
|d2(nspcmx,nspcmx) |--
|z(nspcmx)      |specie.valency
|q(nspcmx)      |mc_ion_instance.q() [specie.valency /mc_evaluator.qstar()]
|ratmov(nspcmx) |mc_ion_instance.rate_spherical_move_
|ratexc(nspcmx) |mc_ion_instance.rate_exchange_
|eps(nspcmx)    |mc_ion_instance.diffusion_coefficient
|qstar          |mc_evaluator.qstar [constants::qstar_factor/[[temperature]]
|itry(nspcmx)   |mc_ion_instance.rate_ion_moves_
|chonly(nspcmx) |mc_ion_instance.channel_only
|nspec          |mc_evaluator.species
|nwh(ntrymx)    | (mc_ion_instance.rate_ion_moves_)
|ntry           |-- (sum itry[..])
|istr           |-- (index of first non-structural ion)


== geom ==

The region specifications

|zl(6)
|rl(6)
|rlvest
|rlcurv
|epsw
|epspr


== patch ==

The 'patches' that are placed on channel protein boundary and used
to calculate PNP energy component

|px(npchmx)	|mc_patch.location.x, mc_enironment.patches
|py(npchmx)	|mc_patch.location.y, mc_enironment.patches
|pz(npchmx)	|mc_patch.location.z, mc_enironment.patches
|h(npchmx)	|mc_evaluator.h; mc_step.h
|ux(npchmx)	|mc_patch.normal.x, mc_enironment.patches
|uy(npchmx)	|mc_patch.normal.y, mc_enironment.patches
|uz(npchmx)	|mc_patch.normal.z, mc_enironment.patches
|a(npchmx)	|mc_patch.area, mc_enironment.patches
|amx(npchmx,npchmx)
|c(npchmx)      |mc_evaluator.c; mc_step.c
|deps		|<<mc_evaluator.dielectric_factor>> == 2(epsw - epspr)/(epsw + epspr)
|rip(ntotmx,npchmx) | ??
|npatch		|mc_environment.patches
|indx(npchmx)   |--
|npch(10)       |--


== moove ==

Data used when moving particles in an MC step

|drmax(2)	|mc_region.max_move
|vin(nspcmx)	| calculated on the fly
|vout(nspcmx)	| calculated on the fly
|rljpin(nspcmx)	|mc_region.radius
|zljpin(nspcmx) |mc_region.length


== gc ==

Data related to salts (particle type sets that are
created and destroyed together.)

|chemp(3)	|log(rtagi) + chex 
|ctarg(3)
|vgc(4,3)	| (Accessible Volume/particle)
|riicrn(4,4)
|rxnew(4)       | mc_create_destroy.particles_.x
|rynew(4)       | mc_create_destroy.particles_.y
|rznew(4)       | mc_create_destroy.particles_.z
|r2new(4)       | mc_create_destroy.particles_.r
|chex(3)	|Unit excess chemical potential (?)
|ctrgcl
|ratgr(3)	| mc_salt.rate_grow
|ratgrt		| -- sum ratgr[..]
|ratreg(4)	|<<mc_region.rate>>
|zcr1(4,nspcmx)	|mc_region.start + mc_ion_instance.radius
|zcr2(4,nspcmx)	|mc_region.length + mc_region.start - mc_ion_instance.radius
|rcr(4,nspcmx)  |mc_region.radius - mc_ion_instance.radius
|iout(4)
|ispcin(3,4)	| mc_salt.components
|igcval(3)
|isalt(3)
|ication(3)
|nsalt		|mc_evaluator.salts_.size
|ntot		|mc_evalautor.size()
|niter
|iter		|mc_evaluator.iter


== names ==
|fion(10)	|ionic_specie.name
|fsalt(10)	|mc_salt.name()
|fgz(10)
|fgin(10)
|fc
|fout
|fh
|fnaca(10,4)
|fdata
|focc
|frdf(10,10)


== profl ==
|athist
|ataccu
|dzg(10,nspcmx)
|drg
|vjz(nspcmx,nzgmx)
|vjin(nspcmx,nrgmx,nrgmx)
|rgz(nspcmx,nzgmx)
|rgin(nspcmx,nrgmx)
|gz(nspcmx,nzgmx)
|gin(nspcmx,nrgmx,nrgmx)
|zinlft
|rinup
|zzreg(0:10,nspcmx)
|dzgi(nspcmx,nzgmx)
|nzg(10,nspcmx)
|nrg
|nrgr
|nrgz
|nzgtot(nspcmx)
|nzreg(nspcmx)
|calgin


== accu ==
|an(nspcmx)
|ah(npchmx)
|anin(4,nspcmx)
|zreg1(4,nspcmx)
|zreg2(4,nspcmx)
|rreg(4,nspcmx)
|cbulk(nspcmx)
|zocc
|indreg(3,nspcmx,nionmx)
|nin(4,nspcmx) 	| mc_ion_instance.size(mc_region)


== adj ==
|amove(2,nspcmx)
|ajump(2,nspcmx)
|ajin(2,nspcmx)
|ajout(2,nspcmx)
|acreat(4,3,2)
|adest(4,3,2)


== bufer ==

Temporary data structures.

|hold(npchmx)	| mc_step.h_old/mc_step.h
|cold(npchmx)	| mc_step.c_old/mc_step.c
|ripnew(nspcmx,npchmx) | (calc on fly)
|riinew(nspcmx,ntotmx) | (calc on fly)
|dc(npchmx)	| -- change in c
|dh(npchmx)	| -- change in h
|distin(4)


== simp ==

Simulation parameters

|nstep	|mc_evaluator.nstep
|naver	|mc_evaluator.naver
|isave  |mc_evaluator.isave


== bulk ==
|zbulk1
|zbulk2
|rbulk
|vbulk
|anaca(nspcmx,4,20000)
|asuba(nspcmx,4,20000)
|ksub


== occ ==
|aocc(3,0:4,0:4,0:4,0:4)
|nfree


== radf ==
|ardf(3,nspcmx,nspcmx)
|rdf(3,nspcmx,nspcmx,nrgmx)
|drdf
|nrdf
|calrdf



!STRUCT
!these vector sizes will have to change dynamically     
!      common/geo/   za0(8)
ra0(8)
ra(8)
ta1(8)
ta2(8)
zl1(6)
rl1(6)

!  zl2(6)
rl2(6)
qpr(12)
al(6)
bl(6)

!  tgalfa(6)
csalfa(6)
alfa(6)
ric
      common/geo/   za0(nring1)
ra0(nring1)
ra(nring1)
ta1(nring1)

     :		  ta2(nring1)
 
     :		  zl1(nring2)
rl1(nring2)
zl2(nring2)
rl2(nring2)

  qpr(12)

  al(6)
bl(6)

  tgalfa(nring2)
csalfa(nring2)
alfa(nring2)
ric

     :		  ringal(nring1+nring2)
irngno(nring1+nring2)

     :		  ringsb(nring1+nring2
2)
uasign(nring1)

     :		  ulsign(nring1)
nline
nwall
narch
nchg
"
    end

    artifact 170287 "TODO"
      stereotype "document"
      associated_artifacts
      end
      comment "2 10 2016

* IDEA: input_help currently uses Boost command line argument
library to manage help
 information. This allowed quick development but is not
 sufficient for our needs. It also brings in a lot of
 unnecessary code associated with managing command line
 parameters.  Additinal missing requirements are:

 ** Allow sub-types and their options to be easily and clearly
 documented.

 ** Move building of documentation from input_base_meta derived
 ctors to a separate method

 # input_base_meta_subtype: Definition of \"subtype\"
 definitions. This should manage the
   label of the subtype and its valid \"non-standard\"
   options. Help documentation for the options should also be
   provided. (see choice_definition idea in trial library)


1 6 2016

* Remove unnecessary cross-dependencies between libraries:

 ** introduce \"manager\" classes for evaluator, particle,
 sampler etc libraries. Refactor functionality
    from the simulator class into the manager class to eliminate
    cross-dependencies.

 ** Each manager class is associated with a corresponding
 input_base_meta class. The base class is
    blind to this association.

 # particle manager class 

 # observer manager class

 # evaluator manager class

 # choice manager

 # remove simulator ref in input_base_meta and derived classes.

2 . 2 . 2011

* implement PNP set_temperature, set_voltage

* add and implement poisson_equations

* run hollerbach test1

* review design:

 ** appropriate factorisation

 ** visibility

* python

 ** external-code interface

  *** push, pull and async possible?

* logging (levels)
"
    end

    artifact 142256 "savestate.jam"
      stereotype "document"
      associated_artifacts
      end
      comment "#
# Rules to generate a source file that captures compilation information
# 

import type ;
type.register SAVESTATE : template ;

import generators ;
generators.register-standard savestate.inline-file : SAVESTATE : CPP ;

import toolset : flags ;
flags verbatim

rule inline-file ( filename : property-set : project name ? )
{
   local l_compname = compiler.name ;
   local l_compver  = compiler.version ;
   local l_maintarg = $(project) ;
   local l_cflags   = $(cflags) $(cxxflags) ;
   local l_ldflags  = $(linkflags) ;
}

actions inline-file
{
   cat $(<) $(>)
   echo \"namespace {\" >> $(>)
   echo \"std::string comp_name{ \\\"\" $(l_compname) \"\\\" };\" >> $(>)
   echo \"std::string comp_ver{ \\\"\" $(l_compver) \"\\\" };\" >> $(>)
   echo \"std::string comp_target{ \\\"\" $(l_maintarget) \"\\\" };\" >> $(>)
   echo -n \"std::string comp_date{ \\\"\" >> $(>)
   date \"+%d-%m-%y-%H:%M:%S\\\" };\" >> $(>)
   echo \"std::string comp_cflags{ \\\"\" $(l_cflags) \"\\\" };\" >> $(>)
   echo \"std::string comp_ldflags{ \\\"\" $(l_ldflags) \"\\\" };\" >> $(>)
}
"
    end

    artifact 229296 "Geometry.tex"
      stereotype "document"
      associated_artifacts
      end
      comment "\\documentclass[a4paper,10pt]{article}
\\usepackage[T1]{fontenc}
\\usepackage[utf8]{inputenc}
\\usepackage{amsmath}
\\usepackage{amssymb}
\\title{Geometry theory used in program}
\\author{Justin Finnerty}
\\date{June 2015}
\\begin{document}
\\maketitle{}

\\section{Solid of revolution}

A solid of revolution is obtained when a 2{D} figure
(the \\textit{lamina}) is rotated around an axis. Our
simulations axes conform to the standard maths notation
of making such an axis of rotation be along the $z$ axis.

\\subsection{Pappus theorems}
\\subsubsection{Surface Area}

\\begin{equation}
S = sd_i \\label{eqn:pappus:surface}
\\end{equation}

The surface of area ($S$) of a solid of revolution is equal to
the product of arc length of the generating curve ($s$) the 
distance travelled by the geometric centroid ($d_i$) of 
the lamina.  The geometric centroid is the standard centroid 
for the lamina being rotated.

(Kern and Bland, \"Theorem of Pappus\" in \"Solid Mensuration with
proofs\", 2nd ed. New York, Wiley, 1948, 110--115)

\\subsubsection{Volume}

\\begin{equation}
V = Ad_i \\label{eqn:pappus:volume}
\\end{equation}

The volume ($V$) of solid of revolution is equal to
the product of area of the lamina ($A$) the 
distance travelled by the geometric centroid ($d_i$) of 
the lamina.  The geometric centroid is the standard 
centroid for the lamina being rotated.

(Kern and Bland, \"Theorem of Pappus\" in \"Solid Mensuration with
proofs\", 2nd ed. New York, Wiley, 1948, 110--115)

\\subsection{Torus}

The equation of a torus is:

\\begin{equation}
(R - \\surd{x^2 + y^2})^2 + z^2 = a^2 \\label{eqb:torus:cart}
\\end{equation}

where $R$ is the distance between the axis of rotation and 
the centre of the lamina circle and $a$ is the radius of
this circle.

In polar coordinates $(u,v \\in{} [0,2\\pi{}])$:

\\begin{align}
x =& (c + a\\cos{v})\\cos{u} \\label{eqn:torus:polar} \\\\
y =& (c + a\\cos{v})\\sin{u} \\nonumber{}\\\\
z =& a\\sin{v} \\nonumber
\\end{align}

where $z$ axis is the axis of rotation, the circle 
being rotated is centred on the $xy$ plane and $u$ is the 
angle around the $z$ axis and $v$ is the angle from
the centre of the circle being rotated.

\\section{Centroid}

The non-trivial centroids are the ones for walls and arcs.
Even in these cases the centroid in the direction of rotation
($u$ in our polar coordinates) is trivial.

We can calculate a centroid by decomposition into parts:

\\begin{equation}
C = \\frac{\\sum{C_i}{A_i}}{\\sum{A_i}} \\label{eqn:centroid:area}
\\end{equation}

where the centroid ($C$) is the area ($A_i$) weighted average
of the centroids ($C_i$) of the parts:

Dividing the original region into two regions of equal area
(along $v$ coordinate) gives the centroid as the average of
these two sub-centroids. This subdivision can be done ad 
infinitum.

\\subsection{Centroid of wall arc from division of area}

Dividing the area of a wall arc starting at $r$ and extending
to radius $r + c$. The centroid radius ($r + a$) will divide the area
into two equal area halves ($A_1, A_0$):

\\begin{align*}
A_1 =& \\pi(r+c)^2 - \\pi(r+a)^2 \\\\
A_0 =& \\pi(r+a)^2 - \\pi(r)^2 \\\\
(r+a)^2 - r^2 =& (r+c)^2 - (r+a)^2 \\\\
2(r+a)^2 =& (r+c)^2 + r^2 \\\\
a =&  \\frac{\\sqrt{(r+c)^2 + r^2}}{\\sqrt{2}} - r
\\end{align*}

\\subsection{Area of arc of rotation}
For an arc centred on the $x$ axis with angle $a$ and
radius $r$ the centroid is given by:

\\begin{align}
x =& r\\left(\\frac{\\sin{a/2}}{a/2}\\right) \\label{eqn:centroid:arc} \\\\
y =& 0 \\nonumber{}
\\end{align}

Intuitively the ratio $\\frac{\\sin{a/2}}{a/2}$ approaches
$1$ as the angle approaches $0$ and $4/\\pi{}$ as the angle
approaches $\\pi{}/2$.

Converting to our arc we get for arc beginning at $v_0$,
ending at $v_1$ and with $v_1 - v_0 = 2a$:

\\begin{align}
x_c =& \\left(c + r \\frac{\\sin{a}}{a} \\cos{(v_0 + a)}\\right) \\cos{u} \\\\
    =& \\left(c + r \\frac{\\sin{a}}{a} \\cos{(v_1 - a)}\\right) \\cos{u} \\\\
y_c =& \\left(c + r \\frac{\\sin{a}}{a} \\cos{(v_0 + a)}\\right) \\sin{u} \\\\
    =& \\left(c + r \\frac{\\sin{a}}{a} \\cos{(v_1 - a)}\\right) \\sin{u} \\\\
z_c =& r (\\sin{(a)}/a) \\sin{(v_0 + a)}
\\end{align}

Using Pappus theorem (Eqn~\\ref{eqn:pappus:surface}) we get

\\begin{align}
d_i =& 2\\pi{}\\left( c + r \\frac{\\sin{a}}{a} \\sin{(v_0 + a)}\\right) \\\\
s =& 4ar \\\\
A =& 8ar\\pi{}\\left( c + r \\frac{\\sin{a}}{a} \\sin{(v_0 + a)}\\right)
\\end{align}

\\end{document}
"
    end

    artifact 338736 "local.jam.tmpl"
      stereotype "document"
      associated_artifacts
      end
      comment "#
# local.jam
#
# Set constants for installation paths
import path ;
path-constant INSTALL_PREFIX : installdir ;
constant BINDIR : bin ; # User programs
constant DATADIR : share ; # Private libraries and static data
constant DOCDIR : [ path.join share doc ] ;
constant HTMLDIR : [ path.join share html ] ;
constant INCDIR : include ;
constant LIBDIR : bin ; # Shared libraries
constant MANDIR  : [ path.join share man1 ] ;

"
    end

    artifact 358320 "Jamfile"
      stereotype "document"
      comment "##START:version
#Butter version 1.2beta.175
##END:version
##START:date
#Mon Jun 13 18:46:48 2016
##END:date
##START:preamble
BUILDDIR = $(SLASH)home$(SLASH)finnerty$(SLASH)src$(SLASH)ionch$(SLASH)BUILD$(SLASH)linux-deb$(SLASH)PNP ;
SubDir TOP ;
OUTPUTDIR = $(BUILDDIR)$(SLASH)$(VARIANT) ;
HDRS +=  src ;
C++FLAGS += -std=c++11 ;
CCFLAGS += -std=c++11 ;
##END:preamble
##START:close
SubInclude TOP src core ;
SubInclude TOP src core core_test ;
SubInclude TOP src evaluator ;
SubInclude TOP src evaluator evaluator_test ;
SubInclude TOP src cscchannel ;
SubInclude TOP src observer ;
SubInclude TOP src particle ;
SubInclude TOP src particle particle_test ;
SubInclude TOP src cscpbc ;
SubInclude TOP src platform ;
SubInclude TOP src platform platform_test ;
SubInclude TOP src trial ;
SubInclude TOP src trial trial_test ;
SubInclude TOP src utility ;
SubInclude TOP src utility util_test ;
##END:close
"
    end

    artifact 364848 "local.jam"
      stereotype "document"
      comment "#
# local.jam
#
# Set constants for installation paths
import path ;
path-constant PREFIX : stage ;
path-constant INSTALL_PREFIX : installdir ;
constant BINDIR : bin ; # User programs
constant DATADIR : share ; # Private libraries and static data
constant DOCDIR : [ path.join share doc ] ;
constant HTMLDIR : [ path.join share html ] ;
constant INCDIR : include ;
constant LIBDIR : bin ; # Shared libraries
constant MANDIR  : [ path.join share man1 ] ;
# External library settings
constant MPI_INC : /usr/local/openmpi/include ;
constant MPI_LIB : /usr/local/openmpi/lib64 ;
constant LAPACKLIB : /opt/intel/mkl/10.2.1.017/lib/emt64 -lmkl_intel_lp64 -lmkl_core -lmkl_sequential ;
constant LAPACKINC : -DUSE_MKL /opt/intel/mkl/10.2.1.017/include ;
constant BOOST_INC : [ os.environ BOOST_INCLUDEDIR ] ;
constant BOOST_LIB :  [ os.environ BOOST_LIBRARYDIR ] ;
#local requirements
project pnp
	: requirements <cflags>\"-ftemplate-depth=150 -fPIC -DHAVE_LLRINT=1 -DHAVE_UNIQPTR=1 -DHAVE_LRINT=1\" <linkflags>\"-fPIC\" ;
import path ;

"
    end
  end
end
